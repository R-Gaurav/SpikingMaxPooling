{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strong-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import collections\n",
    "\n",
    "import nengo_loihi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "insured-survey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 3, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "#train_x[0] # 0 to 255 range.\n",
    "print(train_x.shape)\n",
    "plt.imshow(train_x[0])\n",
    "train_x, test_x = np.moveaxis(train_x, -1, 1), np.moveaxis(test_x, -1, 1)\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "roman-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idg = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    data_format=\"channels_first\",\n",
    ")\n",
    "train_idg.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "classical-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NengoImageIterator(tf.keras.preprocessing.image.Iterator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_data_generator,\n",
    "        x_keys,\n",
    "        x,\n",
    "        y_keys,\n",
    "        y,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        sample_weight=None,\n",
    "        seed=None,\n",
    "        subset=None,\n",
    "        dtype=\"float32\",\n",
    "    ):\n",
    "        assert subset is None, \"Not Implemented\"\n",
    "        assert isinstance(x_keys, (tuple, list))\n",
    "        assert isinstance(y_keys, (tuple, list))\n",
    "        assert isinstance(x, (tuple, list))\n",
    "        assert isinstance(y, (tuple, list))\n",
    "\n",
    "        self.dtype = dtype\n",
    "        self.x_keys = x_keys\n",
    "        self.y_keys = y_keys\n",
    "\n",
    "        x0 = x[0]\n",
    "        assert all(len(xx) == len(x0) for xx in x), (\n",
    "            \"All of the arrays in `x` should have the same length. \"\n",
    "            \"[len(xx) for xx in x] = %s\" % ([len(xx) for xx in x],)\n",
    "        )\n",
    "        assert all(len(yy) == len(x0) for yy in y), (\n",
    "            \"All of the arrays in `y` should have the same length as `x`. \"\n",
    "            \"len(x[0]) = %d, [len(yy) for yy in y] = %s\"\n",
    "            % (len(x0), [len(yy) for yy in y])\n",
    "        )\n",
    "        assert len(x_keys) == len(x)\n",
    "        assert len(y_keys) == len(y)\n",
    "\n",
    "        if sample_weight is not None and len(x0) != len(sample_weight):\n",
    "            raise ValueError(\n",
    "                \"`x[0]` (images tensor) and `sample_weight` \"\n",
    "                \"should have the same length. \"\n",
    "                \"Found: x.shape = %s, sample_weight.shape = %s\"\n",
    "                % (np.asarray(x0).shape, np.asarray(sample_weight).shape)\n",
    "            )\n",
    "\n",
    "        self.x = [\n",
    "            np.asarray(xx, dtype=self.dtype if i == 0 else None)\n",
    "            for i, xx in enumerate(x)\n",
    "        ]\n",
    "        if self.x[0].ndim != 4:\n",
    "            raise ValueError(\n",
    "                \"Input data in `NumpyArrayIterator` \"\n",
    "                \"should have rank 4. You passed an array \"\n",
    "                \"with shape\",\n",
    "                self.x[0].shape,\n",
    "            )\n",
    "\n",
    "        self.y = [np.asarray(yy) for yy in y]\n",
    "        self.sample_weight = (\n",
    "            None if sample_weight is None else np.asarray(sample_weight)\n",
    "        )\n",
    "        self.image_data_generator = image_data_generator\n",
    "        super().__init__(self.x[0].shape[0], batch_size, shuffle, seed)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        print(\"RG, Index Array: \", index_array)\n",
    "        images = self.x[0]\n",
    "        assert images.dtype == self.dtype\n",
    "\n",
    "        n = len(index_array)\n",
    "        batch_x = np.zeros((n,) + images[0].shape, dtype=self.dtype)\n",
    "        for i, j in enumerate(index_array):\n",
    "            x = images[j]\n",
    "            params = self.image_data_generator.get_random_transform(x.shape)\n",
    "            x = self.image_data_generator.apply_transform(x, params)\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "\n",
    "        batch_x_miscs = [xx[index_array] for xx in self.x[1:]]\n",
    "        batch_y_miscs = [yy[index_array] for yy in self.y]\n",
    "\n",
    "        x_pairs = [\n",
    "            (k, self.x_postprocess(k, v))\n",
    "            for k, v in zip(self.x_keys, [batch_x] + batch_x_miscs)\n",
    "        ]\n",
    "        y_pairs = [\n",
    "            (k, self.y_postprocess(k, v)) for k, v in zip(self.y_keys, batch_y_miscs)\n",
    "        ]\n",
    "\n",
    "        output = (\n",
    "            collections.OrderedDict(x_pairs),\n",
    "            collections.OrderedDict(y_pairs),\n",
    "        )\n",
    "\n",
    "        if self.sample_weight is not None:\n",
    "            output += (self.sample_weight[index_array],)\n",
    "        return output\n",
    "\n",
    "    def x_postprocess(self, key, x):\n",
    "        return x if key == \"n_steps\" else x.reshape((x.shape[0], 1, -1))\n",
    "\n",
    "    def y_postprocess(self, key, y):\n",
    "        return y.reshape((y.shape[0], 1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-spare",
   "metadata": {},
   "source": [
    "# ###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welsh-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_l2_loss_range(\n",
    "    y_true, y, sample_weight=None, min_rate=0.0, max_rate=np.inf, percentile=99.0\n",
    "):\n",
    "    # y axes are (batch examples, time (==1), neurons)\n",
    "    assert len(y.shape) == 3\n",
    "    rates = tfp.stats.percentile(y, percentile, axis=(0, 1))\n",
    "    low_error = tf.maximum(0.0, min_rate - rates)\n",
    "    high_error = tf.maximum(0.0, rates - max_rate)\n",
    "    loss = tf.nn.l2_loss(low_error + high_error)\n",
    "\n",
    "    return (sample_weight * loss) if sample_weight is not None else loss\n",
    "\n",
    "\n",
    "def slice_data_dict(data, slice_):\n",
    "    return {key: value[slice_] for key, value in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "swedish-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_last = True\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "n_classes = len(np.unique(train_y))\n",
    "\n",
    "# TensorFlow does not include the label names, so define them manually\n",
    "label_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "assert n_classes == len(label_names)\n",
    "\n",
    "if not channels_last:\n",
    "    train_x = np.transpose(train_x, (0, 3, 1, 2))\n",
    "    test_x = np.transpose(test_x, (0, 3, 1, 2))\n",
    "\n",
    "# convert the images to float32, and rescale to [-1, 1]\n",
    "train_x = train_x.astype(np.float32) / 127.5 - 1\n",
    "test_x = test_x.astype(np.float32) / 127.5 - 1\n",
    "\n",
    "train_t = np.array(tf.one_hot(train_y, n_classes), dtype=np.float32)\n",
    "test_t = np.array(tf.one_hot(test_y, n_classes), dtype=np.float32)\n",
    "\n",
    "train_y = train_y.squeeze()\n",
    "test_y = test_y.squeeze()\n",
    "\n",
    "train_x_flat = train_x.reshape((train_x.shape[0], 1, -1))\n",
    "train_t_flat = train_t.reshape((train_t.shape[0], 1, -1))\n",
    "\n",
    "test_x_flat = test_x.reshape((test_x.shape[0], 1, -1))\n",
    "test_t_flat = test_t.reshape((test_t.shape[0], 1, -1))\n",
    "\n",
    "input_shape = nengo.transforms.ChannelShape(\n",
    "    test_x[0].shape, channels_last=channels_last\n",
    ")\n",
    "assert input_shape.n_channels in (1, 3)\n",
    "assert train_x[0].shape == test_x[0].shape == input_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tested-destruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host: input-layer: conv (1, 1), stride (1, 1), output (32, 32, 4) (4096 neurons, 12 weights)\n",
      "chip: conv-layer1: conv (3, 3), stride (2, 2), output (15, 15, 64) (14400 neurons, 2304 weights)\n",
      "chip: conv-layer2: conv (3, 3), stride (1, 1), output (13, 13, 72) (12168 neurons, 41472 weights)\n",
      "chip: conv-layer3: conv (3, 3), stride (2, 2), output (6, 6, 256) (9216 neurons, 165888 weights)\n",
      "chip: conv-layer4: conv (1, 1), stride (1, 1), output (6, 6, 256) (9216 neurons, 65536 weights)\n",
      "chip: conv-layer5: conv (1, 1), stride (1, 1), output (6, 6, 64) (2304 neurons, 16384 weights)\n",
      "chip: dense-layer: dense 100, output (100,) (100 neurons, 230400 weights)\n",
      "host: output-layer: dense 10, output (10,) (10 neurons, 1000 weights)\n",
      "TOTAL: 51510 neurons, 522996 weights\n"
     ]
    }
   ],
   "source": [
    "max_rate = 150\n",
    "amp = 1.0 / max_rate\n",
    "rate_reg = 1e-3\n",
    "rate_target = max_rate * amp  # must be in amplitude scaled units\n",
    "\n",
    "relu = nengo.SpikingRectifiedLinear(amplitude=amp)\n",
    "chip_neuron = nengo_loihi.neurons.LoihiLIF(amplitude=amp)\n",
    "\n",
    "layer_confs = [\n",
    "    dict(\n",
    "        name=\"input-layer\",\n",
    "        filters=4,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        neuron=relu,\n",
    "        on_chip=False,\n",
    "    ),\n",
    "    dict(name=\"conv-layer1\", filters=64, kernel_size=3, strides=2, block=(8, 8, 16)),\n",
    "    dict(name=\"conv-layer2\", filters=72, kernel_size=3, strides=1, block=(7, 7, 8)),\n",
    "    dict(name=\"conv-layer3\", filters=256, kernel_size=3, strides=2, block=(6, 6, 12)),\n",
    "    dict(name=\"conv-layer4\", filters=256, kernel_size=1, strides=1, block=(6, 6, 24)),\n",
    "    dict(name=\"conv-layer5\", filters=64, kernel_size=1, strides=1, block=(6, 6, 24)),\n",
    "    dict(name=\"dense-layer\", n_neurons=100, block=(50,)),\n",
    "    dict(name=\"output-layer\", n_neurons=10, neuron=None, on_chip=False),\n",
    "]\n",
    "\n",
    "# Create a PresentInput process to show images from the training set sequentially.\n",
    "# Each image is presented for `presentation_time` seconds.\n",
    "# NOTE: this is not used during training, since we get `nengo_dl` to override the\n",
    "# output of this node with the training data.\n",
    "presentation_time = 0.2\n",
    "present_images = nengo.processes.PresentInput(test_x_flat, presentation_time)\n",
    "\n",
    "total_n_neurons = 0\n",
    "total_n_weights = 0\n",
    "\n",
    "with nengo.Network() as net:\n",
    "    net.config[nengo.Ensemble].max_rates = nengo.dists.Choice([max_rate])\n",
    "    net.config[nengo.Ensemble].intercepts = nengo.dists.Choice([0])\n",
    "    net.config[nengo.Connection].synapse = None\n",
    "\n",
    "    # add a configurable keep_history option to Probes (we'll set this\n",
    "    # to False for some probes below)\n",
    "    nengo_dl.configure_settings(keep_history=True)\n",
    "\n",
    "    # this is an optimization to improve the training speed,\n",
    "    # since we won't require stateful behaviour in this example\n",
    "    nengo_dl.configure_settings(stateful=False)\n",
    "\n",
    "    # this sets the amount of smoothing used on the LIF neurons during training\n",
    "    nengo_dl.configure_settings(lif_smoothing=0.01)\n",
    "\n",
    "    # this allows us to set `nengo_loihi` parameters like `on_chip` and `block_shape`\n",
    "    nengo_loihi.add_params(net)\n",
    "\n",
    "    # the input node that will be used to feed in input images\n",
    "    inp = nengo.Node(present_images, label=\"input_node\")\n",
    "\n",
    "    connections = []\n",
    "    transforms = []\n",
    "    layer_probes = []\n",
    "    shape_in = input_shape\n",
    "    x = inp\n",
    "    for k, layer_conf in enumerate(layer_confs):\n",
    "        layer_conf = dict(layer_conf)  # copy, so we don't modify the original\n",
    "        name = layer_conf.pop(\"name\")\n",
    "        neuron_type = layer_conf.pop(\"neuron\", chip_neuron)\n",
    "        on_chip = layer_conf.pop(\"on_chip\", True)\n",
    "        block = layer_conf.pop(\"block\", None)\n",
    "\n",
    "        if block is not None and not channels_last:\n",
    "            # move channels to first index\n",
    "            block = (block[-1],) + block[:-1]\n",
    "\n",
    "        # --- create layer transform\n",
    "        if \"filters\" in layer_conf:\n",
    "            # convolutional layer\n",
    "            n_filters = layer_conf.pop(\"filters\")\n",
    "            kernel_size = layer_conf.pop(\"kernel_size\")\n",
    "            strides = layer_conf.pop(\"strides\", 1)\n",
    "            assert len(layer_conf) == 0, \"Unused fields in conv layer: %s\" % list(\n",
    "                layer_conf\n",
    "            )\n",
    "\n",
    "            kernel_size = (\n",
    "                (kernel_size, kernel_size)\n",
    "                if isinstance(kernel_size, int)\n",
    "                else kernel_size\n",
    "            )\n",
    "            strides = (strides, strides) if isinstance(strides, int) else strides\n",
    "\n",
    "            transform = nengo.Convolution(\n",
    "                n_filters=n_filters,\n",
    "                input_shape=shape_in,\n",
    "                kernel_size=kernel_size,\n",
    "                strides=strides,\n",
    "                padding=\"valid\",\n",
    "                channels_last=channels_last,\n",
    "                init=nengo_dl.dists.Glorot(scale=1.0 / np.prod(kernel_size)),\n",
    "            )\n",
    "            shape_out = transform.output_shape\n",
    "\n",
    "            loc = \"chip\" if on_chip else \"host\"\n",
    "            n_neurons = np.prod(shape_out.shape)\n",
    "            n_weights = np.prod(transform.kernel_shape)\n",
    "            print(\n",
    "                \"%s: %s: conv %s, stride %s, output %s (%d neurons, %d weights)\"\n",
    "                % (\n",
    "                    loc,\n",
    "                    name,\n",
    "                    kernel_size,\n",
    "                    strides,\n",
    "                    shape_out.shape,\n",
    "                    n_neurons,\n",
    "                    n_weights,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            # dense layer\n",
    "            n_neurons = layer_conf.pop(\"n_neurons\")\n",
    "\n",
    "            shape_out = nengo.transforms.ChannelShape((n_neurons,))\n",
    "            transform = nengo.Dense(\n",
    "                (shape_out.size, shape_in.size),\n",
    "                init=nengo_dl.dists.Glorot(),\n",
    "            )\n",
    "\n",
    "            loc = \"chip\" if on_chip else \"host\"\n",
    "            n_weights = np.prod(transform.shape)\n",
    "            print(\n",
    "                \"%s: %s: dense %d, output %s (%d neurons, %d weights)\"\n",
    "                % (loc, name, n_neurons, shape_out.shape, n_neurons, n_weights)\n",
    "            )\n",
    "\n",
    "        assert len(layer_conf) == 0, \"Unused fields in %s: %s\" % (\n",
    "            [name] + list(layer_conf)\n",
    "        )\n",
    "\n",
    "        total_n_neurons += n_neurons\n",
    "        total_n_weights += n_weights\n",
    "\n",
    "        # --- create layer output (Ensemble or Node)\n",
    "        assert on_chip or block is None, \"`block` must be None if off-chip\"\n",
    "\n",
    "        if neuron_type is None:\n",
    "            assert not on_chip, \"Nodes can only be run off-chip\"\n",
    "            y = nengo.Node(size_in=shape_out.size, label=name)\n",
    "        else:\n",
    "            ens = nengo.Ensemble(shape_out.size, 1, neuron_type=neuron_type, label=name)\n",
    "            net.config[ens].on_chip = on_chip\n",
    "            y = ens.neurons\n",
    "\n",
    "            if block is not None:\n",
    "                net.config[ens].block_shape = nengo_loihi.BlockShape(\n",
    "                    block,\n",
    "                    shape_out.shape,\n",
    "                )\n",
    "\n",
    "            # add a probe so we can measure individual layer rates\n",
    "            probe = nengo.Probe(y, synapse=None, label=\"%s_p\" % name)\n",
    "            net.config[probe].keep_history = False\n",
    "            layer_probes.append(probe)\n",
    "\n",
    "        conn = nengo.Connection(x, y, transform=transform)\n",
    "        net.config[conn].pop_type = 32\n",
    "\n",
    "        transforms.append(transform)\n",
    "        connections.append(conn)\n",
    "        x = y\n",
    "        shape_in = shape_out\n",
    "\n",
    "    output_p = nengo.Probe(x, synapse=None, label=\"output_p\")\n",
    "\n",
    "print(\"TOTAL: %d neurons, %d weights\" % (total_n_neurons, total_n_weights))\n",
    "assert len(layer_confs) == len(transforms) == len(connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "plastic-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input and target dictionaries to pass to NengoDL\n",
    "train_inputs = {inp: train_x_flat}\n",
    "train_targets = {output_p: train_t_flat}\n",
    "\n",
    "test_inputs = {inp: test_x_flat}\n",
    "test_targets = {output_p: test_t_flat}\n",
    "for probe in layer_probes:\n",
    "    train_targets[probe] = np.zeros((train_t_flat.shape[0], 1, 0), dtype=np.float32)\n",
    "    test_targets[probe] = np.zeros((test_t_flat.shape[0], 1, 0), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "placed-navigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input-layer: initial weights: 0.416\n",
      "conv-layer1: initial weights: 0.049\n",
      "conv-layer2: initial weights: 0.035\n",
      "conv-layer3: initial weights: 0.023\n",
      "conv-layer4: initial weights: 0.054\n",
      "conv-layer5: initial weights: 0.068\n",
      "dense-layer: initial weights: 0.025\n",
      "output-layer: initial weights: 0.118\n",
      "input-layer: initial rates: 0.215\n",
      "conv-layer1: initial rates: 0.000\n",
      "conv-layer2: initial rates: 0.000\n",
      "conv-layer3: initial rates: 0.000\n",
      "conv-layer4: initial rates: 0.000\n",
      "conv-layer5: initial rates: 0.000\n",
      "dense-layer: initial rates: 0.000\n"
     ]
    }
   ],
   "source": [
    "# --- evaluate layers\n",
    "# use rate neurons always by setting learning_phase_scope\n",
    "with tf.keras.backend.learning_phase_scope(1), nengo_dl.Simulator(\n",
    "    net, minibatch_size=100, progress_bar=False\n",
    ") as sim:\n",
    "    for conf, conn in zip(layer_confs, connections):\n",
    "        weights = sim.model.sig[conn][\"weights\"].initial_value\n",
    "        print(\"%s: initial weights: %0.3f\" % (conf[\"name\"], np.abs(weights).mean()))\n",
    "\n",
    "    sim.run_steps(1, data={inp: train_x_flat[:100]})\n",
    "\n",
    "for conf, layer_probe in zip(layer_confs, layer_probes):\n",
    "    out = sim.data[layer_probe][-1]\n",
    "    print(\"%s: initial rates: %0.3f\" % (conf[\"name\"], np.mean(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "industrial-washington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:01                                               \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'partial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4ff56c669ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrate_reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             losses[probe] = partial(\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mpercentile_l2_loss_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mmin_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partial' is not defined"
     ]
    }
   ],
   "source": [
    "do_training = False\n",
    "\n",
    "checkpoint_base = \"./cifar10_convnet_params\"\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_idg = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    data_format=\"channels_last\" if channels_last else \"channels_first\",\n",
    ")\n",
    "train_idg.fit(train_x)\n",
    "\n",
    "# use rate neurons always by setting learning_phase_scope\n",
    "with tf.keras.backend.learning_phase_scope(1), nengo_dl.Simulator(\n",
    "    net, minibatch_size=batch_size\n",
    ") as sim:\n",
    "\n",
    "    percentile = 99.9\n",
    "\n",
    "    def rate_metric(_, outputs):\n",
    "        # take percentile over all examples, for each neuron\n",
    "        top_rates = tfp.stats.percentile(outputs, percentile, axis=(0, 1))\n",
    "        return tf.reduce_mean(top_rates) / amp\n",
    "\n",
    "    losses = collections.OrderedDict()\n",
    "    metrics = collections.OrderedDict()\n",
    "    loss_weights = collections.OrderedDict()\n",
    "\n",
    "    losses[output_p] = tf.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    metrics[output_p] = \"accuracy\"\n",
    "    loss_weights[output_p] = 1.0\n",
    "\n",
    "    for probe, layer_conf in zip(layer_probes, layer_confs):\n",
    "        metrics[probe] = rate_metric\n",
    "\n",
    "        if layer_conf.get(\"on_chip\", True):\n",
    "            losses[probe] = partial(\n",
    "                percentile_l2_loss_range,\n",
    "                min_rate=0.5 * rate_target,\n",
    "                max_rate=rate_target,\n",
    "                percentile=percentile,\n",
    "            )\n",
    "            loss_weights[probe] = rate_reg\n",
    "        else:\n",
    "            losses[probe] = partial(\n",
    "                percentile_l2_loss_range,\n",
    "                min_rate=0,\n",
    "                max_rate=rate_target,\n",
    "                percentile=percentile,\n",
    "            )\n",
    "            loss_weights[probe] = 10 * rate_reg\n",
    "\n",
    "    sim.compile(\n",
    "        loss=losses,\n",
    "        optimizer=tf.optimizers.Adam(),\n",
    "        metrics=metrics,\n",
    "        loss_weights=loss_weights,\n",
    "    )\n",
    "\n",
    "    if do_training:\n",
    "        # --- train\n",
    "        steps_per_epoch = len(train_x) // batch_size\n",
    "\n",
    "        # Create a NengoImageIterator that will return the appropriate dictionaries\n",
    "        # with augmented images. Since we are using a generator, we need to include\n",
    "        # the `n_steps` parameter so that NengoDL knows how many timesteps are in\n",
    "        # each example (in our case, since we just have static images, it's one).\n",
    "        n = steps_per_epoch * batch_size\n",
    "        n_steps = np.ones((n, 1), dtype=np.int32)\n",
    "        train_data = NengoImageIterator(\n",
    "            image_data_generator=train_idg,\n",
    "            x_keys=[inp.label, \"n_steps\"],\n",
    "            x=[train_x[:n], n_steps],\n",
    "            y_keys=[output_p.label] + [probe.label for probe in layer_probes],\n",
    "            y=[train_t[:n]]\n",
    "            + [np.zeros((n, 1, 0), dtype=np.float32) for _ in layer_probes],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        n_epochs = 100\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            sim.fit(\n",
    "                train_data,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=1,\n",
    "                verbose=2,\n",
    "            )\n",
    "\n",
    "            # report test data statistics\n",
    "            outputs = sim.evaluate(x=test_inputs, y=test_targets, verbose=0)\n",
    "            print(\"Epoch %d test: %s\" % (epoch, outputs))\n",
    "\n",
    "            # save the parameters to the checkpoint\n",
    "            savefile = checkpoint_base\n",
    "            sim.save_params(savefile)\n",
    "            print(\"Saved params to %r\" % savefile)\n",
    "    else:\n",
    "        urlretrieve(\n",
    "            \"https://drive.google.com/uc?export=download&\"\n",
    "            \"id=1jvP8IsdqGH2kn0OJOykJxjBsJLgk8GsY\",\n",
    "            \"%s.npz\" % checkpoint_base,\n",
    "        )\n",
    "        sim.load_params(checkpoint_base)\n",
    "        print(\"Loaded params %r\" % checkpoint_base)\n",
    "\n",
    "    # copy the learned/loaded parameters back to the network, for Loihi simulator\n",
    "    sim.freeze_params(net)\n",
    "\n",
    "    # run the network on some of the train and test data to benchmark performance\n",
    "    try:\n",
    "        train_slice = slice(0, 1000)\n",
    "        train_outputs = sim.evaluate(\n",
    "            x=slice_data_dict(train_inputs, train_slice),\n",
    "            y=slice_data_dict(train_targets, train_slice),\n",
    "            verbose=0,\n",
    "        )\n",
    "        print(\"Final train:\")\n",
    "        for key, val in train_outputs.items():\n",
    "            print(\"  %s: %s\" % (key, val))\n",
    "\n",
    "        # test_slice = slice(None)\n",
    "        test_slice = slice(0, 1000)\n",
    "        test_outputs = sim.evaluate(\n",
    "            x=slice_data_dict(test_inputs, test_slice),\n",
    "            y=slice_data_dict(test_targets, test_slice),\n",
    "            verbose=0,\n",
    "        )\n",
    "        print(\"Final test:\")\n",
    "        for key, val in test_outputs.items():\n",
    "            print(\"  %s: %s\" % (key, val))\n",
    "    except Exception as e:\n",
    "        print(\"Could not compute ANN values on this machine: %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "illegal-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "n_steps =  np.ones((n, 1), dtype=np.int32)\n",
    "train_data = NengoImageIterator(\n",
    "            image_data_generator=train_idg,\n",
    "            x_keys=[inp.label, \"n_steps\"],\n",
    "            x=[train_x[:n], n_steps],\n",
    "            y_keys=[output_p.label] + [probe.label for probe in layer_probes],\n",
    "            y=[train_t[:n]]\n",
    "            + [np.zeros((n, 1, 0), dtype=np.float32) for _ in layer_probes],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "young-nudist",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RG, Index Array:  [59 53 65 97  8 36 73 46 31  0 43 34 76 24 40 13 45 12 92 87 28 61  5 93\n",
      " 86 26 19 89 55  9 22 10 77 57 82 50 88 99 39 21 83 98 69 70 80 18 42  4\n",
      " 60 79 51  1 16 62 25 85 64 20 48 96 44 30 90 84 94 37 38 14  6 68  2  3\n",
      " 49 75 95 15 66 63 58 47 52 27 32 56 67  7 41 71 29 11 72 78 17 54 23 33\n",
      " 81 91 35 74]\n",
      "OrderedDict([('input_node', array([[[ 0.96862745,  0.960777  ,  0.9529191 , ...,  0.33267027,\n",
      "          0.49685147,  0.6486328 ]],\n",
      "\n",
      "       [[ 0.22977978,  0.24546605,  0.14350528, ...,  0.6       ,\n",
      "          0.60784316,  0.5744577 ]],\n",
      "\n",
      "       [[ 0.3009308 ,  0.31534222,  0.3525486 , ...,  0.04186888,\n",
      "         -0.04682839,  0.04936532]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.6767899 , -0.34938443,  0.10551757, ..., -0.461124  ,\n",
      "         -0.44493455, -0.21283475]],\n",
      "\n",
      "       [[ 0.5740807 ,  0.5616173 ,  0.4830731 , ..., -0.02128781,\n",
      "          0.03352775, -0.7528116 ]],\n",
      "\n",
      "       [[-0.02819131,  0.1133584 , -0.02408617, ..., -0.41970524,\n",
      "         -0.23931311, -0.24735111]]], dtype=float32)), ('n_steps', array([[1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1]], dtype=int32))]) OrderedDict([('output_p', array([[[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]], dtype=float32)), ('input-layer_p', array([], shape=(100, 1, 0), dtype=float32)), ('conv-layer1_p', array([], shape=(100, 1, 0), dtype=float32)), ('conv-layer2_p', array([], shape=(100, 1, 0), dtype=float32)), ('conv-layer3_p', array([], shape=(100, 1, 0), dtype=float32)), ('conv-layer4_p', array([], shape=(100, 1, 0), dtype=float32)), ('conv-layer5_p', array([], shape=(100, 1, 0), dtype=float32)), ('dense-layer_p', array([], shape=(100, 1, 0), dtype=float32))])\n",
      "(100, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for x, y in train_data:\n",
    "  print(x, y)\n",
    "  print(y[\"output_p\"].shape)\n",
    "  if k==0:\n",
    "    break\n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-dakota",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
