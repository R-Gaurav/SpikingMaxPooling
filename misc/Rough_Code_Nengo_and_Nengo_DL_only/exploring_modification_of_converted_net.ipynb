{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nengo_dl\n",
    "import nengo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-batch",
   "metadata": {},
   "source": [
    "# TF Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    activation=tf.nn.relu,\n",
    ")(inp)\n",
    "\n",
    "max_pool = tf.keras.layers.MaxPool2D()(conv0)\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    ")(max_pool)\n",
    "\n",
    "# fully connected layer\n",
    "flatten = tf.keras.layers.Flatten()(conv1)\n",
    "dense = tf.keras.layers.Dense(units=10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-candidate",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-extent",
   "metadata": {},
   "source": [
    "# TF Model Compilation and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.optimizers.Adam(0.001),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "  metrics=[tf.metrics.sparse_categorical_accuracy])\n",
    "model.fit(train_images, train_labels, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-texture",
   "metadata": {},
   "source": [
    "# TF Model evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-chester",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-working",
   "metadata": {},
   "source": [
    "# Conversion from TF to spiking Nengo DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-warner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_steps = 40\n",
    "ndl_model = nengo_dl.Converter(model, \n",
    "                               swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "                               scale_firing_rates=100,\n",
    "                               synapse=0.005)\n",
    "\n",
    "with ndl_model.net:\n",
    "  nengo_dl.configure_settings(stateful=False)\n",
    "      \n",
    "with ndl_model.net:\n",
    "  # Output from the first Conv layer.\n",
    "  # ndl_model.layers[conv0].probeable => ('output', 'input', 'output', 'voltage')\n",
    "  conv0_lyr_otpt = nengo.Probe(ndl_model.layers[conv0], attr=\"output\")\n",
    "  # ndl_model.net.ensembles[0].probeable => ('decoded_output', 'input', 'scaled_encoders')\n",
    "  conv0_ens_otpt = nengo.Probe(ndl_model.net.ensembles[0], attr=\"decoded_output\")\n",
    "  \n",
    "  # ndl_model.layers[conv0].ensemble.neurons.probeable => ('output', 'input', 'output', 'voltage')\n",
    "  conv0_lyr_nrns_otpt = nengo.Probe(ndl_model.layers[conv0].ensemble.neurons, attr=\"output\")\n",
    "  # ndl_model.net.ensembles[0].neurons.probeable => ('output', 'input', 'output', 'voltage')\n",
    "  conv0_ens_nrns_otpt = nengo.Probe(ndl_model.net.ensembles[0].neurons, attr=\"output\")\n",
    "  \n",
    "  # Output from max_pool layer.\n",
    "  # ndl_model.layers[max_pool].probeable => ('output',)\n",
    "  #max_pool_otpt = nengo.Probe(ndl_model.layers[max_pool], \"output\")\n",
    "  \n",
    "  # Input to the second Conv layer.\n",
    "  # ndl_model.layers[conv1].probeable => ('output', 'input', 'output', 'voltage')\n",
    "  #conv1_ens_input = nengo.Probe(ndl_model.layers[conv1], attr=\"input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-update",
   "metadata": {},
   "source": [
    "# Nengo-DL model test data creation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_test_images = np.tile(\n",
    "  test_images.reshape((test_images.shape[0], 1, -1)), (1, n_steps, 1))\n",
    "ndl_input = ndl_model.inputs[inp]\n",
    "ndl_output = ndl_model.outputs[dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-morris",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model.net, minibatch_size=100) as sim:\n",
    "  data1 = sim.predict({ndl_input: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-robinson",
   "metadata": {},
   "source": [
    "# Nengo-DL model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data1[ndl_output][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-accent",
   "metadata": {},
   "source": [
    "# Nengo-DL model probes output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data1[conv0_lyr_otpt].shape, data1[conv0_ens_otpt].shape, \n",
    "      data1[conv0_lyr_nrns_otpt].shape, data1[conv0_ens_nrns_otpt].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(21632):\n",
    "  if np.any(data1[conv0_lyr_otpt][0, :, i]):\n",
    "    print(i, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-capitol",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neuron_index = 4319\n",
    "print(data1[conv0_lyr_otpt][0, :, neuron_index])\n",
    "print(data1[conv0_lyr_nrns_otpt][0, :, neuron_index])\n",
    "print(data1[conv0_ens_nrns_otpt][0, :, neuron_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-shoot",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn_from_conv0_to_max_node = ndl_model.net.all_connections[3]\n",
    "print(conn_from_conv0_to_max_node.pre_obj)\n",
    "print(conn_from_conv0_to_max_node.transform)\n",
    "print(conn_from_conv0_to_max_node.synapse)\n",
    "print(conn_from_conv0_to_max_node.function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-proxy",
   "metadata": {},
   "source": [
    "# ################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-cliff",
   "metadata": {},
   "source": [
    "# Nengo-DL model modification (Replacing MaxPooling TensorNode with Custom Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(t, x):\n",
    "  print(x.shape)\n",
    "  print(x[:200])\n",
    "  return x[:5408]\n",
    "\n",
    "with ndl_model.net:\n",
    "  # Create Custom Node.\n",
    "  new_node = nengo.Node(output=func, size_in=21632, label=\"Custome Node\")\n",
    "\n",
    "  conn_from_conv0_to_max_node = ndl_model.net.all_connections[3]\n",
    "\n",
    "  # COnnection from Conv0 to MaxPool node.\n",
    "  nengo.Connection(\n",
    "    conn_from_conv0_to_max_node.pre_obj,\n",
    "    new_node,\n",
    "    transform=conn_from_conv0_to_max_node.transform,\n",
    "    synapse=conn_from_conv0_to_max_node.synapse,\n",
    "    function=conn_from_conv0_to_max_node.function)\n",
    "\n",
    "  # Connection from MaxPool node to Conv1.\n",
    "  conn_from_max_node_to_conv1 = ndl_model.net.all_connections[6]\n",
    "  nengo.Connection(\n",
    "    new_node,\n",
    "    conn_from_max_node_to_conv1.post_obj,\n",
    "    transform=conn_from_max_node_to_conv1.transform,\n",
    "    synapse=conn_from_max_node_to_conv1.synapse,\n",
    "    function=conn_from_max_node_to_conv1.function)\n",
    "\n",
    "  # Remove the old connection to MaxPool node and from MaxPool node, MaxPool node.\n",
    "  ndl_model.net._connections.remove(conn_from_conv0_to_max_node)\n",
    "  ndl_model.net._connections.remove(conn_from_max_node_to_conv1)\n",
    "  ndl_model.net._nodes.remove(conn_from_conv0_to_max_node.post_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-robert",
   "metadata": {},
   "source": [
    "# Check if modification of connection was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-leeds",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndl_model.net.all_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-break",
   "metadata": {},
   "source": [
    "# Execute modified Nengo-DL model with Custom Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-newcastle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model.net, minibatch_size=100) as sim:\n",
    "  data2 = sim.predict({ndl_input: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-lambda",
   "metadata": {},
   "source": [
    "# Modified Nengo-DL model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data2[ndl_output][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-testing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ndl_model.net._connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_model.net.connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_model.net.all_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-broadcasting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for conn in ndl_model.net.all_nodes:\n",
    "  print(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-coordination",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for e, s in zip(data[conv0_ens_otpt][0, -1, :], data[conv0_ens_nrns_otpt][0, -1, :]):\n",
    "#   print(e, s)\n",
    "for i, e in enumerate(data[max_pool_otpt][0, -1, :]):\n",
    "  if e !=0:\n",
    "    print(i, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ndl_model.net.ensembles[0].probeable)\n",
    "print(ndl_model.net.ensembles[0].neurons.probeable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ndl_model.layers[conv0].probeable)\n",
    "print(ndl_model.layers[conv0].ensemble.neurons.probeable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.random.rand(2,  3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = k.flatten()\n",
    "print(m.shape)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = m.reshape(2, 3, 4)\n",
    "print(n.shape)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(k):\n",
    "  k = k.reshape(2, 3, 4)\n",
    "  print(k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k.flatten()\n",
    "print(\"k\", k.shape)\n",
    "reshape(k)\n",
    "print(\"k\", k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-staff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
