{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advanced-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nengo_dl\n",
    "import nengo\n",
    "import nengo_loihi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distinguished-comment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0 3.4.0 3.1.0 1.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__, nengo_dl.__version__, nengo.__version__, nengo_loihi.__version__) # => 2.2.0 3.4.0 3.1.0, 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-exhaust",
   "metadata": {},
   "source": [
    "# Probing neurons in individual Ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continuous-sullivan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ac9d6d30310>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ngo_sim.data[n_probe])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-lloyd",
   "metadata": {},
   "source": [
    "Whichever neuron you choose, after executing the network and plotting the spikes, you will see that the spikes are of amplitude `1/dt = 1000.0` in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ahead-familiar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vdom.v1+json": {
       "attributes": {},
       "tagName": "div"
      },
      "text/html": [
       "\n",
       "                <script>\n",
       "                    if (Jupyter.version.split(\".\")[0] < 5) {\n",
       "                        var pb = document.getElementById(\"38eaaae1-973c-46ae-bc4f-6478acc15ae5\");\n",
       "                        var text = document.createTextNode(\n",
       "                            \"HMTL progress bar requires Jupyter Notebook >= \" +\n",
       "                            \"5.0 or Jupyter Lab. Alternatively, you can use \" +\n",
       "                            \"TerminalProgressBar().\");\n",
       "                        pb.parentNode.insertBefore(text, pb);\n",
       "                    }\n",
       "                </script>\n",
       "                <div id=\"38eaaae1-973c-46ae-bc4f-6478acc15ae5\" style=\"\n",
       "                    width: 100%;\n",
       "                    border: 1px solid #cfcfcf;\n",
       "                    border-radius: 4px;\n",
       "                    text-align: center;\n",
       "                    position: relative;\">\n",
       "                  <div class=\"pb-text\" style=\"\n",
       "                      position: absolute;\n",
       "                      width: 100%;\">\n",
       "                    0%\n",
       "                  </div>\n",
       "                  <div class=\"pb-fill\" style=\"\n",
       "                      background-color: #bdd2e6;\n",
       "                      width: 0%;\">\n",
       "                    <style type=\"text/css\" scoped=\"scoped\">\n",
       "                        @keyframes pb-fill-anim {\n",
       "                            0% { background-position: 0 0; }\n",
       "                            100% { background-position: 100px 0; }\n",
       "                        }\n",
       "                    </style>\n",
       "                    &nbsp;\n",
       "                  </div>\n",
       "                </div>"
      ],
      "text/plain": [
       "HtmlProgressBar cannot be displayed. Please use the TerminalProgressBar. It can be enabled with `nengo.rc['progress']['progress_bar'] = 'nengo.utils.progress.TerminalProgressBar'`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vdom.v1+json": {
       "attributes": {
        "id": "8e77cd95-7a9a-4b10-9fc4-4acdc943f299",
        "style": {
         "border": "1px solid #cfcfcf",
         "borderRadius": "4px",
         "boxSizing": "border-box",
         "position": "relative",
         "textAlign": "center",
         "width": "100%"
        }
       },
       "children": [
        {
         "attributes": {
          "class": "pb-text",
          "style": {
           "position": "absolute",
           "width": "100%"
          }
         },
         "children": [
          "Build finished in 0:00:01."
         ],
         "tagName": "div"
        },
        {
         "attributes": {
          "class": "pb-fill",
          "style": {
           "animation": "none",
           "backgroundColor": "#bdd2e6",
           "backgroundImage": "none",
           "backgroundSize": "100px 100%",
           "width": "100%"
          }
         },
         "children": [
          {
           "attributes": {
            "scoped": "scoped",
            "type": "text/css"
           },
           "children": [
            "\n                        @keyframes pb-fill-anim {\n                            0% { background-position: 0 0; }\n                            100% { background-position: 100px 0; }\n                        }}"
           ],
           "tagName": "style"
          },
          " "
         ],
         "tagName": "div"
        }
       ],
       "tagName": "div"
      },
      "text/html": [
       "<script>\n",
       "              (function () {\n",
       "                  var root = document.getElementById('38eaaae1-973c-46ae-bc4f-6478acc15ae5');\n",
       "                  var text = root.getElementsByClassName('pb-text')[0];\n",
       "                  var fill = root.getElementsByClassName('pb-fill')[0];\n",
       "\n",
       "                  text.innerHTML = 'Build finished in 0:00:01.';\n",
       "                  \n",
       "            fill.style.width = '100%';\n",
       "            fill.style.animation = 'pb-fill-anim 2s linear infinite';\n",
       "            fill.style.backgroundSize = '100px 100%';\n",
       "            fill.style.backgroundImage = 'repeating-linear-gradient(' +\n",
       "                '90deg, #bdd2e6, #edf2f8 40%, #bdd2e6 80%, #bdd2e6)';\n",
       "        \n",
       "                  \n",
       "                fill.style.animation = 'none';\n",
       "                fill.style.backgroundImage = 'none';\n",
       "            \n",
       "              })();\n",
       "        </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vdom.v1+json": {
       "attributes": {},
       "tagName": "div"
      },
      "text/html": [
       "\n",
       "                <script>\n",
       "                    if (Jupyter.version.split(\".\")[0] < 5) {\n",
       "                        var pb = document.getElementById(\"f756fca3-1dec-4efc-a3f5-6d4e4d624582\");\n",
       "                        var text = document.createTextNode(\n",
       "                            \"HMTL progress bar requires Jupyter Notebook >= \" +\n",
       "                            \"5.0 or Jupyter Lab. Alternatively, you can use \" +\n",
       "                            \"TerminalProgressBar().\");\n",
       "                        pb.parentNode.insertBefore(text, pb);\n",
       "                    }\n",
       "                </script>\n",
       "                <div id=\"f756fca3-1dec-4efc-a3f5-6d4e4d624582\" style=\"\n",
       "                    width: 100%;\n",
       "                    border: 1px solid #cfcfcf;\n",
       "                    border-radius: 4px;\n",
       "                    text-align: center;\n",
       "                    position: relative;\">\n",
       "                  <div class=\"pb-text\" style=\"\n",
       "                      position: absolute;\n",
       "                      width: 100%;\">\n",
       "                    0%\n",
       "                  </div>\n",
       "                  <div class=\"pb-fill\" style=\"\n",
       "                      background-color: #bdd2e6;\n",
       "                      width: 0%;\">\n",
       "                    <style type=\"text/css\" scoped=\"scoped\">\n",
       "                        @keyframes pb-fill-anim {\n",
       "                            0% { background-position: 0 0; }\n",
       "                            100% { background-position: 100px 0; }\n",
       "                        }\n",
       "                    </style>\n",
       "                    &nbsp;\n",
       "                  </div>\n",
       "                </div>"
      ],
      "text/plain": [
       "HtmlProgressBar cannot be displayed. Please use the TerminalProgressBar. It can be enabled with `nengo.rc['progress']['progress_bar'] = 'nengo.utils.progress.TerminalProgressBar'`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vdom.v1+json": {
       "attributes": {
        "id": "3cb552e6-8ae9-4d51-9027-840ee2319bae",
        "style": {
         "border": "1px solid #cfcfcf",
         "borderRadius": "4px",
         "boxSizing": "border-box",
         "position": "relative",
         "textAlign": "center",
         "width": "100%"
        }
       },
       "children": [
        {
         "attributes": {
          "class": "pb-text",
          "style": {
           "position": "absolute",
           "width": "100%"
          }
         },
         "children": [
          "Simulation finished in 0:00:01."
         ],
         "tagName": "div"
        },
        {
         "attributes": {
          "class": "pb-fill",
          "style": {
           "animation": "none",
           "backgroundColor": "#bdd2e6",
           "backgroundImage": "none",
           "transition": "width 0.1s linear",
           "width": "100%"
          }
         },
         "children": [
          {
           "attributes": {
            "scoped": "scoped",
            "type": "text/css"
           },
           "children": [
            "\n                        @keyframes pb-fill-anim {\n                            0% { background-position: 0 0; }\n                            100% { background-position: 100px 0; }\n                        }}"
           ],
           "tagName": "style"
          },
          " "
         ],
         "tagName": "div"
        }
       ],
       "tagName": "div"
      },
      "text/html": [
       "<script>\n",
       "              (function () {\n",
       "                  var root = document.getElementById('f756fca3-1dec-4efc-a3f5-6d4e4d624582');\n",
       "                  var text = root.getElementsByClassName('pb-text')[0];\n",
       "                  var fill = root.getElementsByClassName('pb-fill')[0];\n",
       "\n",
       "                  text.innerHTML = 'Simulation finished in 0:00:01.';\n",
       "                  \n",
       "            if (100.0 > 0.) {\n",
       "                fill.style.transition = 'width 0.1s linear';\n",
       "            } else {\n",
       "                fill.style.transition = 'none';\n",
       "            }\n",
       "\n",
       "            fill.style.width = '100.0%';\n",
       "            fill.style.animation = 'none';\n",
       "            fill.style.backgroundImage = 'none'\n",
       "        \n",
       "                  \n",
       "                fill.style.animation = 'none';\n",
       "                fill.style.backgroundImage = 'none';\n",
       "            \n",
       "              })();\n",
       "        </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with nengo.Network() as net:\n",
    "  inp = nengo.Node(10)\n",
    "  ens = nengo.Ensemble(\n",
    "    n_neurons=1,\n",
    "    dimensions=1,\n",
    "    #neuron_type=nengo.LIF(),\n",
    "    #neuron_type=nengo.SpikingRectifiedLinear(),\n",
    "    neuron_type=nengo_loihi.neurons.LoihiSpikingRectifiedLinear(),\n",
    "    encoders=[[1]],\n",
    "    gain=[1],\n",
    "    bias=[0.2],\n",
    "    seed=0\n",
    "  )\n",
    "  nengo.Connection(inp, ens, synapse=None)\n",
    "  n_probe = nengo.Probe(ens.neurons[0], synapse=None)\n",
    "\n",
    "with nengo.Simulator(net) as ngo_sim:\n",
    "  ngo_sim.run(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-vanilla",
   "metadata": {},
   "source": [
    "# Probing neurons in a NengoDL network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-concentrate",
   "metadata": {},
   "source": [
    "## Training and Evaluating TF network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "threaded-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seven-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    activation=tf.nn.relu,\n",
    ")(inp)\n",
    "\n",
    "max_pool = tf.keras.layers.MaxPool2D()(conv0)\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    ")(max_pool)\n",
    "\n",
    "# fully connected layer\n",
    "flatten = tf.keras.layers.Flatten()(conv1)\n",
    "dense = tf.keras.layers.Dense(units=10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "saved-complement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                23050     \n",
      "=================================================================\n",
      "Total params: 41,866\n",
      "Trainable params: 41,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "descending-piano",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3053 - sparse_categorical_accuracy: 0.9413\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0739 - sparse_categorical_accuracy: 0.9779\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9817\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ac9ee4c5050>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.optimizers.Adam(0.001),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "  metrics=[tf.metrics.sparse_categorical_accuracy])\n",
    "model.fit(train_images, train_labels, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "robust-maximum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06150761619210243, 0.9818000197410583]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-citation",
   "metadata": {},
   "source": [
    "## Converting to NengoDL Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brazilian-coral",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:326: UserWarning: Cannot convert max pooling layers to native Nengo objects; consider setting max_to_avg_pool=True to use average pooling instead. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n",
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:588: UserWarning: Activation type <function softmax at 0x2ac9ce581200> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n"
     ]
    }
   ],
   "source": [
    "n_steps, sfr = 40, 100\n",
    "\n",
    "ndl_model = nengo_dl.Converter(\n",
    "  model,\n",
    "  swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "  scale_firing_rates=sfr,\n",
    "  synapse=0.005\n",
    ")\n",
    "\n",
    "with ndl_model.net:\n",
    "  nengo_dl.configure_settings(stateful=False)\n",
    "  \n",
    "  # Probe Conv0 layer.\n",
    "  # Probing ndl_model.layers[conv0].ensemble.neurons is same as Probing ndl_model.layers[conv0]\n",
    "  conv0_lyr_otpt = nengo.Probe(ndl_model.layers[conv0].ensemble.neurons, attr=\"output\", synapse=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "developing-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_test_images = np.tile(\n",
    "  test_images.reshape((test_images.shape[0], 1, -1)), (1, n_steps, 1))\n",
    "ndl_input = ndl_model.inputs[inp]\n",
    "ndl_output = ndl_model.outputs[dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aboriginal-making",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model.net, minibatch_size=100) as ndl_sim:\n",
    "  data1 = ndl_sim.predict({ndl_input: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-session",
   "metadata": {},
   "source": [
    "### Accuracy over first 200 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crazy-director",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data1[ndl_output][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-damage",
   "metadata": {},
   "source": [
    "### Investigating raw output from Conv0 layer before multiplying with `sfr` and `dt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "outdoor-wisconsin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl_sim.data[ndl_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "engaging-federation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 40, 21632)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv0_otpt = data1[conv0_lyr_otpt]\n",
    "conv0_otpt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "nasty-batch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.999999 0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "[0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       9.999999 0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "[0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       9.999999 0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "[0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       9.999999 0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n",
      "[0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       9.999999 0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " 0.       0.       0.       0.       0.       0.       0.       0.      ]\n"
     ]
    }
   ],
   "source": [
    "b = 0\n",
    "for neuron in range(conv0_otpt.shape[-1]):\n",
    "  if np.any(conv0_otpt[0, :, neuron]):\n",
    "    print(conv0_otpt[0, :, neuron])\n",
    "    b+=1\n",
    "  if b == 5: # Print only 5 neurons whose activity is non-zero in any timestep.\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-nursery",
   "metadata": {},
   "source": [
    "### Spikes from Conv0 layer after multiplying with `sfr` and `dt`\n",
    "\n",
    "The output is the number of spikes in a timestep. Here it appears to be `0.99999` i.e. `1` spike per timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "liberal-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv0_spikes_matrix = data1[conv0_lyr_otpt] * sfr * 0.001 # dt = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "revised-satin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999994 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.99999994 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.99999994 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.99999994\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.99999994\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "b = 0\n",
    "for neuron in range(conv0_spikes_matrix.shape[-1]):\n",
    "  if np.any(conv0_spikes_matrix[0, :, neuron]):\n",
    "    print(conv0_spikes_matrix[0, :, neuron])\n",
    "    b+=1\n",
    "  if b == 5: # Print only 5 neurons whose activity is non-zero in any timestep.\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
