{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "psychological-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_paths\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nengo_dl\n",
    "import nengo \n",
    "\n",
    "from configs.exp_configs import tf_exp_cfg as tf_cfg, nengo_dl_cfg as ndl_cfg\n",
    "from utils.cnn_2d_utils import get_2d_cnn_model\n",
    "from utils.nengo_dl_utils import get_nengo_dl_model\n",
    "from utils.base_utils.exp_utils import get_grouped_slices_2d_pooling\n",
    "from utils.base_utils.data_prep_utils import get_batches_of_exp_dataset, get_exp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polish-walnut",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3, 32, 32)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 3, 32, 32)         9         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 30, 30)         216       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 15, 15)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 13, 13)        1152      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2704)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                173120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 175,147\n",
      "Trainable params: 175,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_2d_cnn_model((3, 32, 32), tf_cfg) # Channels first shape (1, 28, 28).\n",
    "model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alone-opera",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:326: UserWarning: Cannot convert max pooling layers to native Nengo objects; consider setting max_to_avg_pool=True to use average pooling instead. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n",
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:588: UserWarning: Activation type <function softmax at 0x2ab9d2560ef0> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n"
     ]
    }
   ],
   "source": [
    "ndl_model = nengo_dl.Converter(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "scenic-atlas",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KerasTensorDict', 'TrackedDict', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_layer_converters', 'allow_fallback', 'converters', 'get_converter', 'inference_only', 'inputs', 'layers', 'max_to_avg_pool', 'model', 'net', 'outputs', 'register', 'scale_firing_rates', 'split_shared_weights', 'swap_activations', 'synapse', 'temporal_model', 'verify']\n"
     ]
    }
   ],
   "source": [
    "print(dir(ndl_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "superb-passion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 26, 26)\n",
      "(24, 11, 11)\n"
     ]
    }
   ],
   "source": [
    "for lyr in ndl_model.model.layers:\n",
    "  if lyr.name in [\"conv2d\", \"conv2d_1\"]:\n",
    "    print(lyr.output.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bridal-recorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nengo_dl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collaborative-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_slices = get_grouped_slices_2d_pooling(pool_size=(2, 2), num_chnls=1, rows=5, cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "federal-memory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grouped_slices) # 10816 == 16 x 26 x 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "introductory-mills",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  5,  6,  2,  3,  7,  8, 10, 11, 15, 16, 12, 13, 17, 18])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_slices[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "backed-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_slices = get_grouped_slices_2d_pooling(pool_size=(2, 2), num_chnls=24, rows=11, cols=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "frequent-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grouped_slices)# 24 x 11 x 11 = 2904 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-irish",
   "metadata": {},
   "source": [
    "# ###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "marked-heating",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:326: UserWarning: Cannot convert max pooling layers to native Nengo objects; consider setting max_to_avg_pool=True to use average pooling instead. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n",
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:588: UserWarning: Activation type <function softmax at 0x2ae894efbb90> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n"
     ]
    }
   ],
   "source": [
    "ndl_model, ngo_probes_lst = get_nengo_dl_model(\n",
    "    (1, 28, 28), tf_cfg, ndl_cfg, mode=\"test\", num_clss=10, max_to_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sonic-click",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21632"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl_model.net.all_connections[3].post_obj.size_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cheap-specific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Connection from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">> <Connection from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">>\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_1.0\">> to <TensorNode \"max_pooling2d_1\">> <Connection from <Neurons of <Ensemble \"conv2d_1.0\">> to <TensorNode \"max_pooling2d_1\">>\n"
     ]
    }
   ],
   "source": [
    "for i, conn in enumerate(ndl_model.net.all_connections):\n",
    "  if (isinstance(conn.post_obj, nengo_dl.tensor_node.TensorNode) and\n",
    "      conn.post_obj.label.startswith(\"max_pooling\")):\n",
    "    print(conn, ndl_model.net.all_connections[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "first-senator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 28, 28)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 26, 26)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 13, 13)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 11, 11)        3480      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 5, 5)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 3, 3)          6944      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 29,730\n",
      "Trainable params: 29,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ndl_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lonely-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_slices_2d_pooling(**kwargs):\n",
    "  \"\"\"\n",
    "  Creates square grouped slices based on the `pool_size`. E.g. for a flattened\n",
    "  array, the indices are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n",
    "  ...] with `pool_size` = (2, 2), `rows=4`, `cols=4`, the flattened array is\n",
    "  actually:\n",
    "  [[0, 1, 2, 3],\n",
    "   [4, 5, 6, 7],\n",
    "   [8, 9, 10, 11],\n",
    "   [12, 13, 14, 15]]\n",
    "\n",
    "  so the returned grouped slices array should be of indices:\n",
    "  [0, 1, 4, 5, 2, 3, 6, 7, 8, 9, 12, 13, 10, 11, 14, 15, ...]\n",
    "\n",
    "  Note: It expects the \"Channels First\" coding of Input/Conv layers. It is also\n",
    "  assumed that the input `rows` and `cols` are of same size and `pool_size` also\n",
    "  has same row/col dimension.\n",
    "\n",
    "  Args:\n",
    "    kwargs <dict>:\n",
    "      pool_size <tuple>: (int, int) for 2D Pooling - (row, col) arrangement.\n",
    "      num_chnls <int>: Number of channels in the reshaped matrix.\n",
    "      rows <int>: Number of rows in the reshaped matrix.\n",
    "      cols <int>: Number of columns in the reshaped matrix.\n",
    "\n",
    "  Returns:\n",
    "    <[int]>\n",
    "  \"\"\"\n",
    "  pool_size, num_chnls, rows, cols = (\n",
    "      kwargs[\"pool_size\"], kwargs[\"num_chnls\"], kwargs[\"rows\"], kwargs[\"cols\"])\n",
    "  matrix = np.arange(rows * cols * num_chnls).reshape((num_chnls, rows, cols))\n",
    "  grouped_slices = np.zeros(rows * cols * num_chnls, dtype=int)\n",
    "  start, slice_len = 0, np.prod(pool_size)\n",
    "\n",
    "  for chnl in range(num_chnls):\n",
    "    for row in range(rows//pool_size[0]):\n",
    "      for col in range(cols//pool_size[1]):\n",
    "        grouped_slices[start:start+slice_len] = (\n",
    "            matrix[chnl, row*pool_size[0]:row*pool_size[0]+pool_size[0],\n",
    "                   col*pool_size[1]:col*pool_size[1]+pool_size[1]]).flatten()\n",
    "        start += slice_len\n",
    "        \n",
    "  return grouped_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regular-yesterday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  3,  4,  9, 10, 12, 13, 18, 19, 21, 22, 27, 28, 30, 31,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_grouped_slices_2d_pooling(pool_size=(2, 2), num_chnls=4, rows=3, cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afraid-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_slices_2d_pooling(is_channels_last=False, **kwargs):\n",
    "  \"\"\"\n",
    "  Creates square grouped slices based on the `pool_size`. E.g. for a flattened\n",
    "  array, the indices are [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n",
    "  ...] with `pool_size` = (2, 2), `rows=4`, `cols=4`, the flattened array is\n",
    "  actually:\n",
    "  [[0, 1, 2, 3],\n",
    "   [4, 5, 6, 7],\n",
    "   [8, 9, 10, 11],\n",
    "   [12, 13, 14, 15]]\n",
    "\n",
    "  so the returned grouped slices array should be of indices:\n",
    "  [0, 1, 4, 5, 2, 3, 6, 7, 8, 9, 12, 13, 10, 11, 14, 15, ...]\n",
    "\n",
    "  Note: It expects the \"Channels First\" coding of Input/Conv layers. It is also\n",
    "  assumed that the input `rows` and `cols` are of same size and `pool_size` also\n",
    "  has same row/col dimension.\n",
    "\n",
    "  Args:\n",
    "    kwargs <dict>:\n",
    "      pool_size <tuple>: (int, int) for 2D Pooling - (row, col) arrangement.\n",
    "      num_chnls <int>: Number of channels in the reshaped matrix.\n",
    "      rows <int>: Number of rows in the reshaped matrix.\n",
    "      cols <int>: Number of columns in the reshaped matrix.\n",
    "\n",
    "  Returns:\n",
    "    <[int]>\n",
    "  \"\"\"\n",
    "  pool_size, num_chnls, rows, cols = (\n",
    "      kwargs[\"pool_size\"], kwargs[\"num_chnls\"], kwargs[\"rows\"], kwargs[\"cols\"])\n",
    "  matrix = np.arange(rows * cols * num_chnls).reshape((rows, cols, num_chnls))\n",
    "#   if is_channels_last:\n",
    "#     matrix = np.moveaxis(matrix, 0, -1)\n",
    "  grouped_slices = np.zeros(rows * cols * num_chnls, dtype=int)\n",
    "  start, slice_len = 0, np.prod(pool_size)\n",
    "\n",
    "  for chnl in range(num_chnls):\n",
    "    for row in range(rows//pool_size[0]):\n",
    "      for col in range(cols//pool_size[1]):\n",
    "#         if is_channels_last:\n",
    "#           grouped_slices[start:start+slice_len] = (\n",
    "#               matrix[row*pool_size[0]:row*pool_size[0]+pool_size[0],\n",
    "#               col*pool_size[1]:col*pool_size[1]+pool_size[1], chnl]).flatten()\n",
    "#         else:\n",
    "          grouped_slices[start:start+slice_len] = (\n",
    "              matrix[row*pool_size[0]:row*pool_size[0]+pool_size[0],\n",
    "              col*pool_size[1]:col*pool_size[1]+pool_size[1], chnl]).flatten()\n",
    "          start += slice_len\n",
    "        \n",
    "  return grouped_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "powerful-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4, 12, 16,  1,  5, 13, 17,  2,  6, 14, 18,  3,  7, 15, 19,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_grouped_slices = get_grouped_slices_2d_pooling(pool_size=(2, 2), num_chnls=4, rows=3, cols=3)\n",
    "cl_grouped_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "promising-invasion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  3,  4,  9, 10, 12, 13, 18, 19, 21, 22, 27, 28, 30, 31,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_grouped_slices_2d_pooling(pool_size=(2, 2), num_chnls=4, rows=3, cols=3, is_channels_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dependent-specification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 4)\n",
      "[[[ 0  9 18 27]\n",
      "  [ 1 10 19 28]\n",
      "  [ 2 11 20 29]]\n",
      "\n",
      " [[ 3 12 21 30]\n",
      "  [ 4 13 22 31]\n",
      "  [ 5 14 23 32]]\n",
      "\n",
      " [[ 6 15 24 33]\n",
      "  [ 7 16 25 34]\n",
      "  [ 8 17 26 35]]]\n"
     ]
    }
   ],
   "source": [
    "matrix_cl = np.moveaxis(matrix, 0, -1)\n",
    "print(matrix_cl.shape)\n",
    "print(matrix_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "extreme-melbourne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  9, 18, 27,  1, 10, 19, 28,  2, 11, 20, 29,  3, 12, 21, 30,  4,\n",
       "       13, 22, 31,  5, 14, 23, 32,  6, 15, 24, 33,  7, 16, 25, 34,  8, 17,\n",
       "       26, 35])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened = matrix_cl.flatten()\n",
    "flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aging-philippines",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  3,  4,  9, 10, 12, 13, 18, 19, 21, 22, 27, 28, 30, 31,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened[cl_grouped_slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aware-breath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  9, 18, 27],\n",
       "        [ 1, 10, 19, 28],\n",
       "        [ 2, 11, 20, 29]],\n",
       "\n",
       "       [[ 3, 12, 21, 30],\n",
       "        [ 4, 13, 22, 31],\n",
       "        [ 5, 14, 23, 32]],\n",
       "\n",
       "       [[ 6, 15, 24, 33],\n",
       "        [ 7, 16, 25, 34],\n",
       "        [ 8, 17, 26, 35]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_matrix_cl = np.reshape(flattened, (3, 3, 4))\n",
    "reshaped_matrix_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-subscriber",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
