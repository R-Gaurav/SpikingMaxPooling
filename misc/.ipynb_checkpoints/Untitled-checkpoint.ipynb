{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "charitable-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import collections\n",
    "\n",
    "import nengo_loihi\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "from configs.exp_configs import tf_exp_cfg as tf_cfg, nengo_dl_cfg as ndl_cfg\n",
    "from utils.base_utils.data_prep_utils import get_batches_of_exp_dataset, get_exp_dataset\n",
    "from utils.base_utils.exp_utils import get_shuffled_lists_in_unison\n",
    "from utils.nengo_dl_utils import get_nengo_dl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medieval-arrest",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:326: UserWarning: Cannot convert max pooling layers to native Nengo objects; consider setting max_to_avg_pool=True to use average pooling instead. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n"
     ]
    }
   ],
   "source": [
    "ndl_model, ngo_probes_lst = get_nengo_dl_model(\n",
    "    (3, 32, 32), tf_cfg, ndl_cfg, mode=\"test\", num_clss=10,\n",
    "    max_to_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "serial-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, _, _ = get_exp_dataset(tf_cfg[\"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "apart-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idg = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1, height_shift_range=0.1, rotation_range=20,\n",
    "    horizontal_flip=True, data_format=\"channels_first\")\n",
    "train_idg.fit(train_x, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "large-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = get_batches_of_exp_dataset(ndl_cfg, ndl_model, ngo_probes_lst, is_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respected-blackberry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_1': array([[[ 0.52970785,  0.58914107,  0.61386853, ...,  0.17098694,\n",
      "          0.17388225,  0.17647064]],\n",
      "\n",
      "       [[ 0.14242302,  0.14115667,  0.13989033, ..., -0.16017927,\n",
      "         -0.14399078, -0.13512635]],\n",
      "\n",
      "       [[-0.2381835 , -0.19567242, -0.14785662, ..., -0.20021376,\n",
      "         -0.23046876, -0.27700269]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.1884422 ,  0.252013  ,  0.30463028, ..., -0.06497534,\n",
      "          0.03411075, -0.1286374 ]],\n",
      "\n",
      "       [[ 0.77580655,  0.77371138,  0.77161628, ..., -0.0375508 ,\n",
      "          0.0069184 ,  0.03529418]],\n",
      "\n",
      "       [[-0.17738906, -0.1607843 , -0.15155597, ..., -0.55841964,\n",
      "         -0.56552613, -0.56476986]]]), 'n_steps': array([[1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1]], dtype=int32), 'dense_1.0.bias': array([[[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        ...,\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]],\n",
      "\n",
      "       [[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        ...,\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]],\n",
      "\n",
      "       [[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        ...,\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        ...,\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]],\n",
      "\n",
      "       [[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        ...,\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]],\n",
      "\n",
      "       [[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        ...,\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]]], dtype=int32)} {'probe': array([[[0., 0., 0., ..., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 1., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[1., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.]]])}\n",
      "(128, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_batches:\n",
    "  print(x, y)\n",
    "  print(y[\"probe\"].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-weekly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
