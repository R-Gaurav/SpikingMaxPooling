{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaurav/miniconda3/envs/nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:360: UserWarning: Layer '<class 'tensorflow.python.keras.layers.normalization_v2.BatchNormalization'>' already has a converter. Overwriting.\n",
      "  \"Layer '%s' already has a converter. Overwriting.\" % keras_layer\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nengo\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import nengo_dl\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (\n",
    "    test_images,\n",
    "    test_labels,\n",
    ") = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# flatten images and add time dimension\n",
    "train_images = train_images.reshape((train_images.shape[0], 1, -1))\n",
    "train_labels = train_labels.reshape((train_labels.shape[0], 1, -1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 1, -1))\n",
    "test_labels = test_labels.reshape((test_labels.shape[0], 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    activation=tf.nn.relu,\n",
    ")(inp)\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    ")(conv0)\n",
    "\n",
    "# fully connected layer\n",
    "flatten = tf.keras.layers.Flatten()(conv1)\n",
    "dense = tf.keras.layers.Dense(units=10)(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = nengo_dl.Converter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 13s 218us/sample - loss: 0.5468 - probe_loss: 0.5468 - probe_sparse_categorical_accuracy: 0.9233 - val_loss: 0.0800 - val_probe_loss: 0.0800 - val_probe_sparse_categorical_accuracy: 0.9760\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0588 - probe_loss: 0.0588 - probe_sparse_categorical_accuracy: 0.9819 - val_loss: 0.0598 - val_probe_loss: 0.0598 - val_probe_sparse_categorical_accuracy: 0.9812\n"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(converter.net, minibatch_size=200) as sim:\n",
    "        # run training\n",
    "        sim.compile(\n",
    "            optimizer=tf.optimizers.Adam(0.001),\n",
    "            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[tf.metrics.sparse_categorical_accuracy],\n",
    "        )\n",
    "        sim.fit(\n",
    "            {converter.inputs[inp]: train_images},\n",
    "            {converter.outputs[dense]: train_labels},\n",
    "            validation_data=(\n",
    "                {converter.inputs[inp]: test_images},\n",
    "                {converter.outputs[dense]: test_labels},\n",
    "            ),\n",
    "            epochs=2,\n",
    "        )\n",
    "\n",
    "        # save the parameters to file\n",
    "        sim.save_params(\"./keras_to_snn_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(\n",
    "    activation,\n",
    "    params_file=\"keras_to_snn_params\",\n",
    "    n_steps=30,\n",
    "    scale_firing_rates=1,\n",
    "    synapse=None,\n",
    "    n_test=400,\n",
    "):\n",
    "    # convert the keras model to a nengo network\n",
    "    nengo_converter = nengo_dl.Converter(\n",
    "        model,\n",
    "        swap_activations={tf.nn.relu: activation},\n",
    "        scale_firing_rates=scale_firing_rates,\n",
    "        synapse=synapse,\n",
    "    )\n",
    "\n",
    "    # get input/output objects\n",
    "    nengo_input = nengo_converter.inputs[inp]\n",
    "    nengo_output = nengo_converter.outputs[dense]\n",
    "\n",
    "    # add a probe to the first convolutional layer to record activity.\n",
    "    # we'll only record from a subset of neurons, to save memory.\n",
    "    sample_neurons = np.linspace(\n",
    "        0,\n",
    "        np.prod(conv0.shape[1:]),\n",
    "        1000,\n",
    "        endpoint=False,\n",
    "        dtype=np.int32,\n",
    "    )\n",
    "    with nengo_converter.net:\n",
    "        conv0_probe = nengo.Probe(nengo_converter.layers[conv0][sample_neurons])\n",
    "\n",
    "    # repeat inputs for some number of timesteps\n",
    "    tiled_test_images = np.tile(test_images[:n_test], (1, n_steps, 1))\n",
    "\n",
    "    # set some options to speed up simulation\n",
    "    with nengo_converter.net:\n",
    "        nengo_dl.configure_settings(stateful=False)\n",
    "\n",
    "    # build network, load in trained weights, run inference on test images\n",
    "    with nengo_dl.Simulator(\n",
    "        nengo_converter.net, minibatch_size=10, progress_bar=False\n",
    "    ) as nengo_sim:\n",
    "        nengo_sim.load_params(params_file)\n",
    "        data = nengo_sim.predict({nengo_input: tiled_test_images})\n",
    "\n",
    "    # compute accuracy on test data, using output of network on\n",
    "    # last timestep\n",
    "    print(\"Nengo Output Shape: \", data[nengo_output].shape, \"Probe Output Shape: \", data[conv0_probe].shape)\n",
    "    predictions = np.argmax(data[nengo_output][:, -1], axis=-1)\n",
    "    accuracy = (predictions == test_labels[:n_test, 0, 0]).mean()\n",
    "    print(f\"Test accuracy: {100 * accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 99.00%\n"
     ]
    }
   ],
   "source": [
    "run_network(\n",
    "    activation=nengo.SpikingRectifiedLinear(), scale_firing_rates=250, n_steps=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
