{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "treated-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nengo_dl\n",
    "import nengo\n",
    "import random\n",
    "import _init_paths\n",
    "\n",
    "from utils.base_utils.exp_utils import get_grouped_slices_2d_pooling\n",
    "from utils.nengo_dl_utils import get_max_pool_global_net\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-fisher",
   "metadata": {},
   "source": [
    "# Change `channels_last` to `channels_first`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "designing-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Image Data Format:  channels_last\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Image Data Format: \", tf.keras.backend.image_data_format())\n",
    "#tf.keras.backend.set_image_data_format(\"channels_first\") -> For some reason this automatic change doesn't work.\n",
    "#print(\"Changed Image Data Format to: \", tf.keras.backend.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comfortable-valuable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "# Make Channels First image coding.\n",
    "train_images, test_images = np.expand_dims(train_images, -1), np.expand_dims(test_images, -1)\n",
    "train_images, test_images = np.moveaxis(train_images, -1, 1), np.moveaxis(test_images, -1, 1)\n",
    "print(train_images.shape, test_images.shape) # Channels First coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-equity",
   "metadata": {},
   "source": [
    "# TF Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "precious-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(1, 28, 28)) # Channels First\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(inp)\n",
    "\n",
    "# Default pool_size = (2,2), padding = \"valid\", data_format = \"channels_first\" (changed programmatically above).\n",
    "max_pool0 = tf.keras.layers.MaxPool2D(data_format=\"channels_first\")(conv0) \n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(max_pool0)\n",
    "\n",
    "# max_pool1 = tf.keras.layers.MaxPool2D(data_format=\"channels_first\")(conv1) \n",
    "\n",
    "# conv2 = tf.keras.layers.Conv2D(\n",
    "#     filters=64,\n",
    "#     kernel_size=3,\n",
    "#     strides=2,\n",
    "#     activation=tf.nn.relu,\n",
    "#     data_format=\"channels_first\"\n",
    "# )(max_pool1)\n",
    "\n",
    "\n",
    "# fully connected layer\n",
    "flatten = tf.keras.layers.Flatten()(conv1)\n",
    "dense = tf.keras.layers.Dense(units=10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instrumental-color",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 28, 28)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 26, 26)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 13, 13)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 6, 6)          18496     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                23050     \n",
      "=================================================================\n",
      "Total params: 41,866\n",
      "Trainable params: 41,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-stationery",
   "metadata": {},
   "source": [
    "## TF Model Compilation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sought-shakespeare",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2592 - sparse_categorical_accuracy: 0.9471\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9790\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9828\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0462 - sparse_categorical_accuracy: 0.9856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b30bff35750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.optimizers.Adam(0.001),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "  metrics=[tf.metrics.sparse_categorical_accuracy])\n",
    "model.fit(train_images, train_labels, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chicken-standing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06449099630117416, 0.9837999939918518]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-romance",
   "metadata": {},
   "source": [
    "# Check Nengo DL MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stunning-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:326: UserWarning: Cannot convert max pooling layers to native Nengo objects; consider setting max_to_avg_pool=True to use average pooling instead. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n",
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:588: UserWarning: Activation type <function softmax at 0x2b30a5615cb0> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n"
     ]
    }
   ],
   "source": [
    "n_steps, sfr = 40, 100\n",
    "radius = 1000/sfr\n",
    "\n",
    "np.random.seed(100)\n",
    "ndl_model_1 = nengo_dl.Converter(model, \n",
    "                               swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "                               scale_firing_rates=sfr,\n",
    "                               synapse=0.005)\n",
    "\n",
    "with ndl_model_1.net:\n",
    "  nengo_dl.configure_settings(stateful=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-distribution",
   "metadata": {},
   "source": [
    "## Explicitly add the synapse between the Conv layer and the MaxPool layer (existing bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "professional-wilson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: <Connection from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">> None\n",
      "After: <Connection from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">> Lowpass(tau=0.005)\n"
     ]
    }
   ],
   "source": [
    "# BUG: https://github.com/nengo/nengo-dl/issues/214\n",
    "\n",
    "print(\"Before:\", ndl_model_1.net._connections[3], ndl_model_1.net._connections[3].synapse)\n",
    "ndl_model_1.net._connections[3].synapse = nengo.Lowpass(0.005)\n",
    "print(\"After:\", ndl_model_1.net._connections[3], ndl_model_1.net._connections[3].synapse)\n",
    "\n",
    "# print(\"Before:\", ndl_model_1.net._connections[7], ndl_model_1.net._connections[7].synapse)\n",
    "# ndl_model_1.net._connections[7].synapse = nengo.Lowpass(0.005)\n",
    "# print(\"After:\", ndl_model_1.net._connections[7], ndl_model_1.net._connections[7].synapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "organizational-sugar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Connection at 0x2b30bffbdf50 from <Node \"conv2d.0.bias\"> to <Node \"conv2d.0.bias_relay\">>,\n",
       " <Connection at 0x2b30bfc2d210 from <Node \"conv2d.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d.0\">>>,\n",
       " <Connection at 0x2b314272a910 from <Node \"input_1\"> to <Neurons of <Ensemble \"conv2d.0\">>>,\n",
       " <Connection at 0x2b30bdb03790 from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">>,\n",
       " <Connection at 0x2b31427461d0 from <Node \"conv2d_1.0.bias\"> to <Node \"conv2d_1.0.bias_relay\">>,\n",
       " <Connection at 0x2b310bfa7fd0 from <Node \"conv2d_1.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>,\n",
       " <Connection at 0x2b31427464d0 from <TensorNode \"max_pooling2d\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>,\n",
       " <Connection at 0x2b3142746790 from <Node \"dense.0.bias\"> to <TensorNode \"dense.0\">>,\n",
       " <Connection at 0x2b31427466d0 from <Neurons of <Ensemble \"conv2d_1.0\">> to <TensorNode \"dense.0\">>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl_model_1.net._connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "international-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_test_images = np.tile(\n",
    "  test_images.reshape((test_images.shape[0], 1, -1)), (1, n_steps, 1))\n",
    "ndl_input_1 = ndl_model_1.inputs[inp]\n",
    "ndl_output_1 = ndl_model_1.outputs[dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "warming-aspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model_1.net, minibatch_size=100) as sim:\n",
    "  data1 = sim.predict({ndl_input_1: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suited-reading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data1[ndl_output_1][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-settle",
   "metadata": {},
   "source": [
    "# Replace the Nengo-DL MaxPool TensorNode with the custom Max Pool Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "historical-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the grouped slices for 2x2 MaxPooling.\n",
    "grouped_slices_1 = get_grouped_slices_2d_pooling(pool_size=(2, 2), num_chnls=32, rows=26, cols=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-kazakhstan",
   "metadata": {},
   "source": [
    "## Connect the max_pool_layer1 to the prev and next Conv (Ensemble).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surgical-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ndl_model_1.net: \n",
    "  conn_from_conv0_to_max_pool = ndl_model_1.net.all_connections[3]\n",
    "  conn_from_max_pool_to_conv1 = ndl_model_1.net.all_connections[6]\n",
    "  \n",
    "  # Get the MaxPool Global Network.\n",
    "  max_pool_layer_1 = get_max_pool_global_net(21632, radius=3, sf=1.2) # 32 x 26 x 26 = 21632 from the prev Conv layer.\n",
    "  \n",
    "  # Connection from Conv0 to max_pool_layer_1.\n",
    "  nengo.Connection(\n",
    "      conn_from_conv0_to_max_pool.pre_obj[grouped_slices_1], #These are of type nengo.ensemble.Neurons\n",
    "      max_pool_layer_1.input,\n",
    "      transform=conn_from_conv0_to_max_pool.transform,\n",
    "      synapse=conn_from_conv0_to_max_pool.synapse,\n",
    "      function=conn_from_conv0_to_max_pool.function\n",
    "      )\n",
    "\n",
    "  # Connection from max_pool_layer_1 to Conv1.\n",
    "  nengo.Connection(\n",
    "      max_pool_layer_1.output,\n",
    "      conn_from_max_pool_to_conv1.post_obj, # These are of type nengo.ensemble.Neurons\n",
    "      transform=conn_from_max_pool_to_conv1.transform,\n",
    "      synapse=conn_from_max_pool_to_conv1.synapse,\n",
    "      function=conn_from_max_pool_to_conv1.function\n",
    "      )\n",
    "  \n",
    "  # Remove old connections.\n",
    "  ndl_model_1.net._connections.remove(conn_from_conv0_to_max_pool)\n",
    "  ndl_model_1.net._connections.remove(conn_from_max_pool_to_conv1)\n",
    "  ndl_model_1.net._nodes.remove(conn_from_conv0_to_max_pool.post_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-baseball",
   "metadata": {},
   "source": [
    "## Check the new connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vulnerable-competition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Connection at 0x2b30bffbdf50 from <Node \"conv2d.0.bias\"> to <Node \"conv2d.0.bias_relay\">>,\n",
       " <Connection at 0x2b30bfc2d210 from <Node \"conv2d.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d.0\">>>,\n",
       " <Connection at 0x2b314272a910 from <Node \"input_1\"> to <Neurons of <Ensemble \"conv2d.0\">>>,\n",
       " <Connection at 0x2b31427461d0 from <Node \"conv2d_1.0.bias\"> to <Node \"conv2d_1.0.bias_relay\">>,\n",
       " <Connection at 0x2b310bfa7fd0 from <Node \"conv2d_1.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>,\n",
       " <Connection at 0x2b3142746790 from <Node \"dense.0.bias\"> to <TensorNode \"dense.0\">>,\n",
       " <Connection at 0x2b31427466d0 from <Neurons of <Ensemble \"conv2d_1.0\">> to <TensorNode \"dense.0\">>,\n",
       " <Connection at 0x2b32127ce0d0 from <Neurons of <Ensemble \"conv2d.0\">>[[    0     1    26 ... 21605 21630 21631]] to <Node (unlabeled) at 0x2b315ede53d0>>,\n",
       " <Connection at 0x2b32127ce110 from <Node (unlabeled) at 0x2b315ee24390> to <Neurons of <Ensemble \"conv2d_1.0\">>>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl_model_1.net._connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-speed",
   "metadata": {},
   "source": [
    "# Check the Nengo-DL model with Custom MaxPooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "developmental-acoustic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:03:08                                                      \n",
      "Optimization finished in 1:18:59                                               \n",
      "Construction finished in 0:01:21                                               \n",
      "Constructing graph: build stage finished in 0:00:01                            \r"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model_1.net, minibatch_size=100) as sim:\n",
    "  data2 = sim.predict({ndl_input_1: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "saved-plant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data2[ndl_output_1][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
