{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "treated-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nengo_dl\n",
    "import nengo\n",
    "import random\n",
    "import _init_paths\n",
    "\n",
    "from utils.base_utils.exp_utils import get_grouped_slices_2d_pooling\n",
    "from utils.nengo_dl_utils import get_max_pool_global_net\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-fisher",
   "metadata": {},
   "source": [
    "# Change `channels_last` to `channels_first`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "designing-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Image Data Format:  channels_last\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Image Data Format: \", tf.keras.backend.image_data_format())\n",
    "#tf.keras.backend.set_image_data_format(\"channels_first\") -> For some reason this automatic change doesn't work.\n",
    "#print(\"Changed Image Data Format to: \", tf.keras.backend.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comfortable-valuable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "# Make Channels First image coding.\n",
    "train_images, test_images = np.expand_dims(train_images, -1), np.expand_dims(test_images, -1)\n",
    "train_images, test_images = np.moveaxis(train_images, -1, 1), np.moveaxis(test_images, -1, 1)\n",
    "print(train_images.shape, test_images.shape) # Channels First coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-equity",
   "metadata": {},
   "source": [
    "# TF Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "precious-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(1, 28, 28)) # Channels First\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(inp)\n",
    "\n",
    "# Default pool_size = (2,2), padding = \"valid\", data_format = \"channels_first\" (changed programmatically above).\n",
    "max_pool0 = tf.keras.layers.MaxPool2D(data_format=\"channels_first\")(conv0) \n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(max_pool0)\n",
    "\n",
    "# max_pool1 = tf.keras.layers.MaxPool2D(data_format=\"channels_first\")(conv1) \n",
    "\n",
    "# conv2 = tf.keras.layers.Conv2D(\n",
    "#     filters=64,\n",
    "#     kernel_size=3,\n",
    "#     strides=2,\n",
    "#     activation=tf.nn.relu,\n",
    "#     data_format=\"channels_first\"\n",
    "# )(max_pool1)\n",
    "\n",
    "\n",
    "# fully connected layer\n",
    "flatten = tf.keras.layers.Flatten()(conv1)\n",
    "dense = tf.keras.layers.Dense(units=10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instrumental-color",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 28, 28)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 26, 26)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 13, 13)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 6, 6)          18496     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                23050     \n",
      "=================================================================\n",
      "Total params: 41,866\n",
      "Trainable params: 41,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "advanced-agriculture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d/Identity:0 max_pooling2d/Identity:0 conv2d_1/Identity:0\n"
     ]
    }
   ],
   "source": [
    "print(conv0.name, max_pool0.name, conv1.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-stationery",
   "metadata": {},
   "source": [
    "## TF Model Compilation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sought-shakespeare",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2590 - sparse_categorical_accuracy: 0.9478\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0705 - sparse_categorical_accuracy: 0.9789\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9824\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b5cbe15fad0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.optimizers.Adam(0.001),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "  metrics=[tf.metrics.sparse_categorical_accuracy])\n",
    "model.fit(train_images, train_labels, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chicken-standing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0694713443517685, 0.9815000295639038]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-romance",
   "metadata": {},
   "source": [
    "# Check Nengo DL MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stunning-edition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:326: UserWarning: Cannot convert max pooling layers to native Nengo objects; consider setting max_to_avg_pool=True to use average pooling instead. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n",
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:588: UserWarning: Activation type <function softmax at 0x2b5c422c6cb0> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n"
     ]
    }
   ],
   "source": [
    "n_steps, sfr = 40, 100\n",
    "radius = 1000/sfr\n",
    "\n",
    "np.random.seed(100)\n",
    "ndl_model_1 = nengo_dl.Converter(model, \n",
    "                               swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "                               scale_firing_rates=sfr,\n",
    "                               synapse=0.005)\n",
    "\n",
    "with ndl_model_1.net:\n",
    "  nengo_dl.configure_settings(stateful=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-distribution",
   "metadata": {},
   "source": [
    "## Explicitly add the synapse between the Conv layer and the MaxPool layer (NengoDL existing bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "professional-wilson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: <Connection from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">> None\n",
      "After: <Connection from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">> Lowpass(tau=0.005)\n"
     ]
    }
   ],
   "source": [
    "# BUG: https://github.com/nengo/nengo-dl/issues/214\n",
    "\n",
    "print(\"Before:\", ndl_model_1.net._connections[3], ndl_model_1.net._connections[3].synapse)\n",
    "ndl_model_1.net._connections[3].synapse = nengo.Lowpass(0.005)\n",
    "print(\"After:\", ndl_model_1.net._connections[3], ndl_model_1.net._connections[3].synapse)\n",
    "\n",
    "# print(\"Before:\", ndl_model_1.net._connections[7], ndl_model_1.net._connections[7].synapse)\n",
    "# ndl_model_1.net._connections[7].synapse = nengo.Lowpass(0.005)\n",
    "# print(\"After:\", ndl_model_1.net._connections[7], ndl_model_1.net._connections[7].synapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "organizational-sugar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Connection at 0x2b5ca40fe5d0 from <Node \"conv2d.0.bias\"> to <Node \"conv2d.0.bias_relay\">>,\n",
       " <Connection at 0x2b5cbe1c9d10 from <Node \"conv2d.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d.0\">>>,\n",
       " <Connection at 0x2b5cbff1e890 from <Node \"input_1\"> to <Neurons of <Ensemble \"conv2d.0\">>>,\n",
       " <Connection at 0x2b5cbef81a10 from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">>,\n",
       " <Connection at 0x2b5cbe2fec50 from <Node \"conv2d_1.0.bias\"> to <Node \"conv2d_1.0.bias_relay\">>,\n",
       " <Connection at 0x2b5cbe2fead0 from <Node \"conv2d_1.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>,\n",
       " <Connection at 0x2b5cfae35150 from <TensorNode \"max_pooling2d\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>,\n",
       " <Connection at 0x2b5cfae35390 from <Node \"dense.0.bias\"> to <TensorNode \"dense.0\">>,\n",
       " <Connection at 0x2b5cfae352d0 from <Neurons of <Ensemble \"conv2d_1.0\">> to <TensorNode \"dense.0\">>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl_model_1.net._connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "international-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_test_images = np.tile(\n",
    "  test_images.reshape((test_images.shape[0], 1, -1)), (1, n_steps, 1))\n",
    "ndl_input_1 = ndl_model_1.inputs[inp]\n",
    "ndl_output_1 = ndl_model_1.outputs[dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "warming-aspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model_1.net, minibatch_size=100) as sim:\n",
    "  data1 = sim.predict({ndl_input_1: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suited-reading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data1[ndl_output_1][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-settle",
   "metadata": {},
   "source": [
    "# Replace the Nengo-DL MaxPool TensorNode with the custom Max Pool Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "historical-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the grouped slices for 2x2 MaxPooling.\n",
    "grouped_slices_1 = get_grouped_slices_2d_pooling(pool_size=(2, 2), num_chnls=32, rows=26, cols=26)\n",
    "conn_from_conv0_to_max_pool = ndl_model_1.net.all_connections[3]\n",
    "conn_from_max_pool_to_conv1 = ndl_model_1.net.all_connections[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-kazakhstan",
   "metadata": {},
   "source": [
    "## Connect the max_pool_layer1 to the prev and next Conv (Ensemble).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surgical-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ndl_model_1.net:   \n",
    "  # Get the MaxPool Global Network.\n",
    "  max_pool_layer_1 = get_max_pool_global_net((32, 26, 26), radius=3, sf=1.2) # 32 x 26 x 26 = 21632 from the prev Conv layer.\n",
    "  \n",
    "  # Connection from Conv0 to max_pool_layer_1.\n",
    "  nengo.Connection(\n",
    "      conn_from_conv0_to_max_pool.pre_obj[grouped_slices_1], #These are of type nengo.ensemble.Neurons\n",
    "      max_pool_layer_1.input,\n",
    "      transform=conn_from_conv0_to_max_pool.transform,\n",
    "      synapse=conn_from_conv0_to_max_pool.synapse,\n",
    "      function=conn_from_conv0_to_max_pool.function\n",
    "      )\n",
    "\n",
    "  # Connection from max_pool_layer_1 to Conv1.\n",
    "  nengo.Connection(\n",
    "      max_pool_layer_1.output,\n",
    "      conn_from_max_pool_to_conv1.post_obj, # These are of type nengo.ensemble.Neurons\n",
    "      transform=conn_from_max_pool_to_conv1.transform,\n",
    "      synapse=conn_from_max_pool_to_conv1.synapse,\n",
    "      function=conn_from_max_pool_to_conv1.function\n",
    "      )\n",
    "  \n",
    "  # Remove old connections.\n",
    "  ndl_model_1.net._connections.remove(conn_from_conv0_to_max_pool)\n",
    "  ndl_model_1.net._connections.remove(conn_from_max_pool_to_conv1)\n",
    "  ndl_model_1.net._nodes.remove(conn_from_conv0_to_max_pool.post_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-baseball",
   "metadata": {},
   "source": [
    "## Check the new connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vulnerable-competition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Connection at 0x2b5ca40fe5d0 from <Node \"conv2d.0.bias\"> to <Node \"conv2d.0.bias_relay\">>,\n",
       " <Connection at 0x2b5cbe1c9d10 from <Node \"conv2d.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d.0\">>>,\n",
       " <Connection at 0x2b5cbff1e890 from <Node \"input_1\"> to <Neurons of <Ensemble \"conv2d.0\">>>,\n",
       " <Connection at 0x2b5cbe2fec50 from <Node \"conv2d_1.0.bias\"> to <Node \"conv2d_1.0.bias_relay\">>,\n",
       " <Connection at 0x2b5cbe2fead0 from <Node \"conv2d_1.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>,\n",
       " <Connection at 0x2b5cfae35390 from <Node \"dense.0.bias\"> to <TensorNode \"dense.0\">>,\n",
       " <Connection at 0x2b5cfae352d0 from <Neurons of <Ensemble \"conv2d_1.0\">> to <TensorNode \"dense.0\">>,\n",
       " <Connection at 0x2b5d9c068c10 from <Neurons of <Ensemble \"conv2d.0\">>[[    0     1    26 ... 21605 21630 21631]] to <Node (unlabeled) at 0x2b5cfb65f450>>,\n",
       " <Connection at 0x2b5d9c068c50 from <Node (unlabeled) at 0x2b5cfb65f390> to <Neurons of <Ensemble \"conv2d_1.0\">>>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl_model_1.net._connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-speed",
   "metadata": {},
   "source": [
    "# Check the Nengo-DL model with Custom MaxPooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "developmental-acoustic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:02:06                                                      \n",
      "|                     #    Optimizing graph                           | 0:04:47\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/graph_optimizer.py\u001b[0m in \u001b[0;36mremove_reset_incs\u001b[0;34m(operators)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                 \u001b[0mnew_operators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c90093387ee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m with nengo_dl.Simulator(\n\u001b[0;32m----> 2\u001b[0;31m   ndl_model_1.net, minibatch_size=100) as sim:\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mndl_input_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mndl_test_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/simulator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, network, dt, seed, model, device, unroll_simulation, minibatch_size, progress_bar)\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                 \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m             )\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/tensor_graph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, dt, unroll_simulation, minibatch_size, device, progress, seed)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mold_operators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msimp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimplifications\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                     \u001b[0moperators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# group mergeable operators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/graph_optimizer.py\u001b[0m in \u001b[0;36mremove_reset_incs\u001b[0;34m(operators)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;31m# replace incer with setter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                 \u001b[0mnew_operators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m                 \u001b[0mignore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model_1.net, minibatch_size=100) as sim:\n",
    "  data2 = sim.predict({ndl_input_1: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "saved-plant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data2[ndl_output_1][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
