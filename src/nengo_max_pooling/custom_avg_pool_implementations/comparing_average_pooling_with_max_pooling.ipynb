{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southeast-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nengo_dl\n",
    "import nengo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aggregate-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accessible-agreement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-jones",
   "metadata": {},
   "source": [
    "# TF Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polyphonic-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    activation=tf.nn.relu,\n",
    ")(inp)\n",
    "\n",
    "# Default pool_size = (2,2), padding = \"valid\", data_format = \"channels_last\".\n",
    "max_pool0 = tf.keras.layers.MaxPool2D()(conv0) \n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    ")(max_pool0)\n",
    "\n",
    "max_pool1 = tf.keras.layers.MaxPool2D()(conv1) \n",
    "\n",
    "conv2 = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    ")(max_pool1)\n",
    "\n",
    "\n",
    "# fully connected layer\n",
    "flatten = tf.keras.layers.Flatten()(conv2)\n",
    "dense = tf.keras.layers.Dense(units=10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loving-unemployment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 56,394\n",
      "Trainable params: 56,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-pearl",
   "metadata": {},
   "source": [
    "# TF Model Compilation and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interim-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3602 - sparse_categorical_accuracy: 0.9233\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0812 - sparse_categorical_accuracy: 0.9749\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9793\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aaec3f95b10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.optimizers.Adam(0.001),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "  metrics=[tf.metrics.sparse_categorical_accuracy])\n",
    "model.fit(train_images, train_labels, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-nebraska",
   "metadata": {},
   "source": [
    "# TF Model evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "phantom-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07999689877033234, 0.9739000201225281]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-billion",
   "metadata": {},
   "source": [
    "# Conversion from TF to spiking Nengo DL model (max_to_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "authentic-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:326: UserWarning: Cannot convert max pooling layers to native Nengo objects; consider setting max_to_avg_pool=True to use average pooling instead. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n",
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:588: UserWarning: Activation type <function softmax at 0x2aaeb5775cb0> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n"
     ]
    }
   ],
   "source": [
    "n_steps = 40\n",
    "np.random.seed(100)\n",
    "ndl_model_1 = nengo_dl.Converter(model, \n",
    "                               swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "                               scale_firing_rates=5,\n",
    "                               max_to_avg_pool=False,\n",
    "                               synapse=0.005)\n",
    "\n",
    "with ndl_model_1.net:\n",
    "  nengo_dl.configure_settings(stateful=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-carolina",
   "metadata": {},
   "source": [
    "## Nengo-DL model test data creation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "shaped-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_test_images = np.tile(\n",
    "  test_images.reshape((test_images.shape[0], 1, -1)), (1, n_steps, 1))\n",
    "ndl_input_1 = ndl_model_1.inputs[inp]\n",
    "ndl_output_1 = ndl_model_1.outputs[dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cardiovascular-photograph",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model_1.net, minibatch_size=100) as sim:\n",
    "  data1 = sim.predict({ndl_input_1: ndl_test_images})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-ending",
   "metadata": {},
   "source": [
    "## Nengo-DL model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proved-beads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6669\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data1[ndl_output_1][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-average",
   "metadata": {},
   "source": [
    "# Conversion from TF to spiking Nengo DL model (max_to_avg_pool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deluxe-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 40\n",
    "np.random.seed(100)\n",
    "ndl_model_2 = nengo_dl.Converter(model, \n",
    "                               swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "                               scale_firing_rates=5,\n",
    "                               max_to_avg_pool=True,\n",
    "                               synapse=0.005)\n",
    "\n",
    "with ndl_model_2.net:\n",
    "  nengo_dl.configure_settings(stateful=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-spell",
   "metadata": {},
   "source": [
    "## Nengo-DL model test data creation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "public-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_test_images = np.tile(\n",
    "  test_images.reshape((test_images.shape[0], 1, -1)), (1, n_steps, 1))\n",
    "ndl_input_2 = ndl_model_2.inputs[inp]\n",
    "ndl_output_2 = ndl_model_2.outputs[dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "three-compiler",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model_2.net, minibatch_size=100) as sim:\n",
    "  data2 = sim.predict({ndl_input_2: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-bulletin",
   "metadata": {},
   "source": [
    "## Nengo-DL model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "checked-challenge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data2[ndl_output_2][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
