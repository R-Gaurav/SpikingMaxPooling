{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civic-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nengo_dl\n",
    "import nengo\n",
    "import matplotlib.pyplot as plt\n",
    "from nengo.utils.matplotlib import rasterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "static-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "classical-poison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-sight",
   "metadata": {},
   "source": [
    "# TF Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weird-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(1, 28, 28)) # Channels first.\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=8,\n",
    "    kernel_size=3,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(inp)\n",
    "\n",
    "# Default pool_size = (2,2), padding = \"valid\", data_format = \"channels_last\".\n",
    "max_pool = tf.keras.layers.MaxPool2D(data_format = \"channels_first\")(conv0) \n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(max_pool)\n",
    "\n",
    "# Default pool_size = (2,2), padding = \"valid\", data_format = \"channels_last\".\n",
    "max_pool_1 = tf.keras.layers.MaxPool2D(data_format = \"channels_first\")(conv1) \n",
    "\n",
    "conv2 = tf.keras.layers.Conv2D(\n",
    "    filters=24,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(max_pool_1)\n",
    "\n",
    "# fully connected layer\n",
    "flatten = tf.keras.layers.Flatten()(conv2)\n",
    "dense = tf.keras.layers.Dense(units=10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "charged-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 28, 28)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 26, 26)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 13, 13)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 11, 11)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 5, 5)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 3, 3)          3480      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 6,898\n",
      "Trainable params: 6,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-stylus",
   "metadata": {},
   "source": [
    "# TF Model Compilation and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "worldwide-amazon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Channels first coding.\n",
    "train_images = train_images.reshape([train_images.shape[0], 1] + list(train_images.shape[1:])) # (60000, 1, 28, 28)\n",
    "test_images = test_images.reshape([test_images.shape[0], 1] + list(test_images.shape[1:]))\n",
    "\n",
    "print(train_images.shape, test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cloudy-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8338 - sparse_categorical_accuracy: 0.8315\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1351 - sparse_categorical_accuracy: 0.9592\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0926 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0730 - sparse_categorical_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2afafff9e7d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.optimizers.Adam(0.001),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "  metrics=[tf.metrics.sparse_categorical_accuracy])\n",
    "model.fit(train_images, train_labels, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-housing",
   "metadata": {},
   "source": [
    "# TF Model evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "included-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07142002880573273, 0.9797000288963318]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-breach",
   "metadata": {},
   "source": [
    "# Conversion from TF to spiking Nengo DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loose-lancaster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:326: UserWarning: Cannot convert max pooling layers to native Nengo objects; consider setting max_to_avg_pool=True to use average pooling instead. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n",
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:588: UserWarning: Activation type <function softmax at 0x2afae53a28c0> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n"
     ]
    }
   ],
   "source": [
    "n_steps, sfr = 40, 25\n",
    "np.random.seed(100)\n",
    "ndl_model = nengo_dl.Converter(model, \n",
    "                               swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "                               #scale_firing_rates=25, # ISI Nengo DL Acc: 73.5, 74.5\n",
    "                               #scale_firing_rates=50, # ISI Nengo DL Acc: 74\n",
    "                               #scale_firing_rates=100, # ISI Nengo DL Acc: 72.5\n",
    "                               # scale_firing_rates=500, # ISI Nengo DL Acc: 75.5\n",
    "                               scale_firing_rates=sfr,\n",
    "                               synapse=0.005)\n",
    "\n",
    "with ndl_model.net:\n",
    "  nengo_dl.configure_settings(stateful=False)\n",
    "  conv0_probe = nengo.Probe(ndl_model.layers[conv0]) # Probe All Neurons.\n",
    "  conv1_probe = nengo.Probe(ndl_model.layers[conv1])\n",
    "  conv2_probe = nengo.Probe(ndl_model.layers[conv2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aggressive-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Connection from <Node \"conv2d.0.bias\"> to <Node \"conv2d.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Node \"input_1\"> to <Neurons of <Ensemble \"conv2d.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_1.0.bias\"> to <Node \"conv2d_1.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_1.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <TensorNode \"max_pooling2d\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_1.0\">> to <TensorNode \"max_pooling2d_1\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_2.0.bias\"> to <Node \"conv2d_2.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_2.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_2.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <TensorNode \"max_pooling2d_1\"> to <Neurons of <Ensemble \"conv2d_2.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Node \"dense.0.bias\"> to <TensorNode \"dense.0\">>  | SYNAPSE:  None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_2.0\">> to <TensorNode \"dense.0\">>  | SYNAPSE:  Lowpass(tau=0.005)\n"
     ]
    }
   ],
   "source": [
    "for conn in ndl_model.net._connections:\n",
    "  print(conn, \" | SYNAPSE: \", conn.synapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "educational-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_model.net._connections[6].synapse = nengo.Lowpass(0.005)\n",
    "ndl_model.net._connections[10].synapse = nengo.Lowpass(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "grave-workplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Connection from <Node \"conv2d.0.bias\"> to <Node \"conv2d.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Node \"input_1\"> to <Neurons of <Ensemble \"conv2d.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_1.0.bias\"> to <Node \"conv2d_1.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_1.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <TensorNode \"max_pooling2d\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>  | SYNAPSE:  Lowpass(tau=0.005)\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_1.0\">> to <TensorNode \"max_pooling2d_1\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_2.0.bias\"> to <Node \"conv2d_2.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_2.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_2.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <TensorNode \"max_pooling2d_1\"> to <Neurons of <Ensemble \"conv2d_2.0\">>>  | SYNAPSE:  Lowpass(tau=0.005)\n",
      "<Connection from <Node \"dense.0.bias\"> to <TensorNode \"dense.0\">>  | SYNAPSE:  None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_2.0\">> to <TensorNode \"dense.0\">>  | SYNAPSE:  Lowpass(tau=0.005)\n"
     ]
    }
   ],
   "source": [
    "for conn in ndl_model.net._connections:\n",
    "  print(conn, \" | SYNAPSE: \", conn.synapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-weather",
   "metadata": {},
   "source": [
    "# Nengo-DL model test data creation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "industrial-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_test_images = np.tile(\n",
    "  test_images.reshape((test_images.shape[0], 1, -1)), (1, n_steps, 1))\n",
    "ndl_input = ndl_model.inputs[inp]\n",
    "ndl_output = ndl_model.outputs[dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ancient-capture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model.net, minibatch_size=100) as sim:\n",
    "  data1 = sim.predict({ndl_input: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-twins",
   "metadata": {},
   "source": [
    "# Nengo-DL model accuracy (first 200 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reliable-description",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data1[ndl_output][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-collect",
   "metadata": {},
   "source": [
    "## Plot the spike output of `Conv0`, `Conv1`, `Conv2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "empty-batch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv0_spikes = data1[conv0_probe]\n",
    "\n",
    "test_samples, sim_steps, n_neurons = conv0_spikes.shape\n",
    "random_neurons = np.random.choice(n_neurons, 64, replace=False)\n",
    "plt.figure(figsize=(16, 6))\n",
    "rasterplot(np.arange(0, sim_steps)*1e-3, conv0_spikes[0, :, random_neurons].T*sfr*0.001) # For test_sample: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ongoing-sitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv1_spikes = data1[conv1_probe]\n",
    "\n",
    "test_samples, sim_steps, n_neurons = conv1_spikes.shape\n",
    "random_neurons = np.random.choice(n_neurons, 64, replace=False)\n",
    "plt.figure(figsize=(16, 6))\n",
    "rasterplot(np.arange(0, sim_steps)*1e-3, conv1_spikes[0, :, random_neurons].T*sfr*0.001) # For test_sample: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "banned-tablet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv2_spikes = data1[conv2_probe]\n",
    "\n",
    "test_samples, sim_steps, n_neurons = conv2_spikes.shape\n",
    "random_neurons = np.random.choice(n_neurons, 64, replace=False)\n",
    "plt.figure(figsize=(16, 6))\n",
    "rasterplot(np.arange(0, sim_steps)*1e-3, conv2_spikes[0, :, random_neurons].T*sfr*0.001) # For test_sample: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-resolution",
   "metadata": {},
   "source": [
    "# ###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-cleaner",
   "metadata": {},
   "source": [
    "# Nengo-DL model modification (Replacing MaxPooling TensorNode with Custom Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "optimum-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = 4\n",
    "NEURONS_LAST_SPIKED_TS_1, NEURONS_LATEST_ISI_1 = np.zeros((8, 26, 26)), np.ones((8, 26, 26))*np.inf\n",
    "MAX_POOL_MASK_1 = np.ones((8, 26, 26))/num_x\n",
    "\n",
    "def isi_based_max_pooling_mp_1(t, inp):\n",
    "  inp = inp.reshape(8, 26, 26) # Channels first.\n",
    "  ret = np.zeros((8, 13, 13)) # Channels first.\n",
    "  \n",
    "  ##################### Normal MaxPooling with np.max() function. #####################\n",
    "#   for chnl in range(inp.shape[0]): # For each channel, calculate the MaxPooled values.\n",
    "#     for r in range(13):\n",
    "#       for c in range(13):\n",
    "#         ret[chnl, r, c] = np.max(inp[chnl, r*2:r*2+2, c*2:c*2+2]) # Channels first\n",
    "#   #####################################################################################\n",
    "  \n",
    "  \n",
    "  ##################### MaxPooling with ISI based method. ##############################\n",
    "  \n",
    "  def _isi_max_pool_algorithm(t, x, r1, r2, c1, c2, chnl):\n",
    "    int_t = int(t*1000.0)\n",
    "    # Get the local copies of updated NEURONS_LAST_SPIKED_TS, NEURONS_LATEST_ISI, and MAX_POOL_MASK for\n",
    "    # each timestep.\n",
    "    neurons_last_spiked_ts = NEURONS_LAST_SPIKED_TS_1[chnl, r1:r2, c1:c2].flatten()\n",
    "    neurons_latest_isi = NEURONS_LATEST_ISI_1[chnl, r1:r2, c1:c2].flatten()\n",
    "    max_pool_mask = MAX_POOL_MASK_1[chnl, r1:r2, c1:c2].flatten()\n",
    "    \n",
    "    spiked_neurons_mask = np.logical_not(np.isin(x, 0))\n",
    "    if np.all(spiked_neurons_mask == False):\n",
    "      return 0\n",
    "    \n",
    "    if np.any(neurons_last_spiked_ts[spiked_neurons_mask]):\n",
    "      neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "      neurons_isi_to_be_updated = neurons_last_spiked_ts_mask & spiked_neurons_mask\n",
    "      neurons_latest_isi[neurons_isi_to_be_updated] = int_t - neurons_last_spiked_ts[neurons_isi_to_be_updated]\n",
    "      max_pool_mask[:] = np.zeros(num_x)\n",
    "      ############################\n",
    "      neurons_idxs_with_min_isi = np.where(neurons_latest_isi == np.amin(neurons_latest_isi))\n",
    "      spike_val, mask_idx = 0, neurons_idxs_with_min_isi[0][0]\n",
    "      for idx in neurons_idxs_with_min_isi[0]:\n",
    "        if x[idx] > spike_val:\n",
    "          spike_val = x[idx]\n",
    "          mask_idx = idx\n",
    "      max_pool_mask[mask_idx] = 1.0\n",
    "      #############################\n",
    "      #max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "      neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "      \n",
    "      NEURONS_LAST_SPIKED_TS_1[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "      NEURONS_LATEST_ISI_1[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "      MAX_POOL_MASK_1[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "      \n",
    "      return np.dot(max_pool_mask, x)\n",
    "    \n",
    "    #####################################################################################\n",
    "    # Come to this block only if the currently spiked neurons did not spike earlier. Even if we have another `neuron`\n",
    "    # with previous ISI calculated, it may be too early to consider that the `neuron` has a higher synapsed value\n",
    "    # i.e. reached to a higher stable rate. So output the spike value of the currently spiked neuron as it can have a\n",
    "    # higher synpased value.\n",
    "    else:\n",
    "      if np.min(neurons_latest_isi) != np.inf:\n",
    "        max_pool_mask[:] = np.zeros(num_x)\n",
    "        max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "        neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "      else:\n",
    "        neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "        max_pool_mask[:] = np.zeros(num_x)\n",
    "        # Instead of Winner Take All, output the value of the neuron which spiked latest i.e. in this current timestep.\n",
    "        max_pool_mask[np.argmax(neurons_last_spiked_ts)] = 1.0\n",
    "    #####################################################################################\n",
    "    \n",
    "    ########################## WINNER TAKE ALL ############################################\n",
    "#     else:\n",
    "#       if np.min(neurons_latest_isi) != np.inf:\n",
    "#         max_pool_mask[:] = np.zeros(num_x)\n",
    "#         max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "#         neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#       else:\n",
    "#         if np.any(neurons_last_spiked_ts):\n",
    "#           neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "#           minimum_last_spiked_ts = np.min(neurons_last_spiked_ts[neurons_last_spiked_ts_mask])\n",
    "#           first_spike_neuron_index = np.where(neurons_last_spiked_ts == minimum_last_spiked_ts)[0][0]\n",
    "#           max_pool_mask[:] = np.zeros(num_x)\n",
    "#           max_pool_mask[first_spike_neuron_index] = 1.0\n",
    "#           neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#         else:\n",
    "#           neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#           max_pool_mask[:] = np.zeros(num_x)\n",
    "#           max_pool_mask[np.where(neurons_last_spiked_ts)[0][0]] = 1.0\n",
    "    #############################################################################################\n",
    "       \n",
    "      NEURONS_LAST_SPIKED_TS_1[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "      NEURONS_LATEST_ISI_1[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "      MAX_POOL_MASK_1[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "      return np.dot(max_pool_mask, x)\n",
    "    \n",
    "  for chnl in range(inp.shape[0]):\n",
    "    for r in range(13):\n",
    "      for c in range(13):\n",
    "        ret[chnl, r, c] = _isi_max_pool_algorithm(\n",
    "            t, inp[chnl, r*2:r*2+2, c*2:c*2+2].flatten(), r*2, r*2+2, c*2, c*2+2, chnl)\n",
    "  \n",
    "  return ret.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "anticipated-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = 4\n",
    "NEURONS_LAST_SPIKED_TS_2, NEURONS_LATEST_ISI_2 = np.zeros((16, 11, 11)), np.ones((16, 11, 11))*np.inf\n",
    "MAX_POOL_MASK_2 = np.ones((16, 11, 11))/num_x\n",
    "\n",
    "def isi_based_max_pooling_mp_2(t, inp):\n",
    "  inp = inp.reshape(16, 11, 11) # Channels first.\n",
    "  ret = np.zeros((16, 5, 5)) # Channels first.\n",
    "  \n",
    "  ##################### Normal MaxPooling with np.max() function. #####################\n",
    "#   for chnl in range(inp.shape[0]): # For each channel, calculate the MaxPooled values.\n",
    "#     for r in range(5):\n",
    "#       for c in range(5):\n",
    "#         ret[chnl, r, c] = np.max(inp[chnl, r*2:r*2+2, c*2:c*2+2]) # Channels first\n",
    "  #####################################################################################\n",
    "  \n",
    "  \n",
    "#   ##################### MaxPooling with ISI based method. ##############################\n",
    "  \n",
    "  def _isi_max_pool_algorithm(t, x, r1, r2, c1, c2, chnl):\n",
    "    int_t = int(t*1000.0)\n",
    "    # Get the local copies of updated NEURONS_LAST_SPIKED_TS, NEURONS_LATEST_ISI, and MAX_POOL_MASK for\n",
    "    # each timestep.\n",
    "    neurons_last_spiked_ts = NEURONS_LAST_SPIKED_TS_2[chnl, r1:r2, c1:c2].flatten()\n",
    "    neurons_latest_isi = NEURONS_LATEST_ISI_2[chnl, r1:r2, c1:c2].flatten()\n",
    "    max_pool_mask = MAX_POOL_MASK_2[chnl, r1:r2, c1:c2].flatten()\n",
    "    \n",
    "    spiked_neurons_mask = np.logical_not(np.isin(x, 0))\n",
    "    if np.all(spiked_neurons_mask == False):\n",
    "      return 0\n",
    "    \n",
    "    if np.any(neurons_last_spiked_ts[spiked_neurons_mask]):\n",
    "      neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "      neurons_isi_to_be_updated = neurons_last_spiked_ts_mask & spiked_neurons_mask\n",
    "      neurons_latest_isi[neurons_isi_to_be_updated] = int_t - neurons_last_spiked_ts[neurons_isi_to_be_updated]\n",
    "      max_pool_mask[:] = np.zeros(num_x)\n",
    "      ############################\n",
    "      neurons_idxs_with_min_isi = np.where(neurons_latest_isi == np.amin(neurons_latest_isi))\n",
    "      spike_val, mask_idx = 0, neurons_idxs_with_min_isi[0][0]\n",
    "      for idx in neurons_idxs_with_min_isi[0]:\n",
    "        if x[idx] > spike_val:\n",
    "          spike_val = x[idx]\n",
    "          mask_idx = idx\n",
    "      max_pool_mask[mask_idx] = 1.0\n",
    "      #############################\n",
    "      #max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "      neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "      \n",
    "      NEURONS_LAST_SPIKED_TS_2[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "      NEURONS_LATEST_ISI_2[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "      MAX_POOL_MASK_2[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "      \n",
    "      return np.dot(max_pool_mask, x)\n",
    "    \n",
    "     #####################################################################################\n",
    "    # Come to this block only if the currently spiked neurons did not spike earlier. Even if we have another `neuron`\n",
    "    # with previous ISI calculated, it may be too early to consider that the `neuron` has a higher synapsed value\n",
    "    # i.e. reached to a higher stable rate. So output the spike value of the currently spiked neuron as it can have a\n",
    "    # higher synpased value.\n",
    "    else:\n",
    "      if np.min(neurons_latest_isi) != np.inf:\n",
    "        max_pool_mask[:] = np.zeros(num_x)\n",
    "        max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "        neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "      else:\n",
    "        neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "        max_pool_mask[:] = np.zeros(num_x)\n",
    "        # Instead of Winner Take All, output the value of the neuron which spiked latest i.e. in this current timestep.\n",
    "        max_pool_mask[np.argmax(neurons_last_spiked_ts)] = 1.0\n",
    "    #####################################################################################\n",
    "    \n",
    "    ########################## WINNER TAKE ALL ############################################\n",
    "#     else:\n",
    "#       if np.min(neurons_latest_isi) != np.inf:\n",
    "#         max_pool_mask[:] = np.zeros(num_x)\n",
    "#         max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "#         neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#       else:\n",
    "#         if np.any(neurons_last_spiked_ts):\n",
    "#           neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "#           minimum_last_spiked_ts = np.min(neurons_last_spiked_ts[neurons_last_spiked_ts_mask])\n",
    "#           first_spike_neuron_index = np.where(neurons_last_spiked_ts == minimum_last_spiked_ts)[0][0]\n",
    "#           max_pool_mask[:] = np.zeros(num_x)\n",
    "#           max_pool_mask[first_spike_neuron_index] = 1.0\n",
    "#           neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#         else:\n",
    "#           neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#           max_pool_mask[:] = np.zeros(num_x)\n",
    "#           max_pool_mask[np.where(neurons_last_spiked_ts)[0][0]] = 1.0\n",
    "    #############################################################################################\n",
    "       \n",
    "      NEURONS_LAST_SPIKED_TS_2[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "      NEURONS_LATEST_ISI_2[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "      MAX_POOL_MASK_2[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "      return np.dot(max_pool_mask, x)\n",
    "    \n",
    "  for chnl in range(inp.shape[0]):\n",
    "    for r in range(5):\n",
    "      for c in range(5):\n",
    "        ret[chnl, r, c] = _isi_max_pool_algorithm(\n",
    "            t, inp[chnl, r*2:r*2+2, c*2:c*2+2].flatten(), r*2, r*2+2, c*2, c*2+2, chnl)\n",
    "  \n",
    "  return ret.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acquired-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ndl_model.net:\n",
    "  # Create Custom Node.\n",
    "  new_node_1 = nengo.Node(output=isi_based_max_pooling_mp_1, size_in=5408, label=\"Custom Node\")\n",
    "  new_node_2 = nengo.Node(output=isi_based_max_pooling_mp_2, size_in=1936, label=\"Custom Node\")\n",
    "\n",
    "  conn_from_conv0_to_max_node_1 = ndl_model.net.all_connections[3]\n",
    "  # COnnection from Conv0 to MaxPool node.\n",
    "  nengo.Connection(\n",
    "    conn_from_conv0_to_max_node_1.pre_obj,\n",
    "    new_node_1,\n",
    "    transform=conn_from_conv0_to_max_node_1.transform,\n",
    "    synapse=conn_from_conv0_to_max_node_1.synapse,\n",
    "    function=conn_from_conv0_to_max_node_1.function)\n",
    "\n",
    "  # Connection from MaxPool node to Conv1.\n",
    "  conn_from_max_node_1_to_conv1 = ndl_model.net.all_connections[6]\n",
    "  nengo.Connection(\n",
    "    new_node_1,\n",
    "    conn_from_max_node_1_to_conv1.post_obj,\n",
    "    transform=conn_from_max_node_1_to_conv1.transform,\n",
    "    synapse=conn_from_max_node_1_to_conv1.synapse,\n",
    "    function=conn_from_max_node_1_to_conv1.function)\n",
    "  \n",
    "  #################################################################\n",
    "  \n",
    "  conn_from_conv0_to_max_node_2 = ndl_model.net.all_connections[7]\n",
    "  # COnnection from Conv0 to MaxPool node.\n",
    "  nengo.Connection(\n",
    "    conn_from_conv0_to_max_node_2.pre_obj,\n",
    "    new_node_2,\n",
    "    transform=conn_from_conv0_to_max_node_2.transform,\n",
    "    synapse=conn_from_conv0_to_max_node_2.synapse,\n",
    "    function=conn_from_conv0_to_max_node_2.function)\n",
    "\n",
    "  # Connection from MaxPool node to Conv1.\n",
    "  conn_from_max_node_2_to_conv1 = ndl_model.net.all_connections[10]\n",
    "  nengo.Connection(\n",
    "    new_node_2,\n",
    "    conn_from_max_node_2_to_conv1.post_obj,\n",
    "    transform=conn_from_max_node_2_to_conv1.transform,\n",
    "    synapse=conn_from_max_node_2_to_conv1.synapse,\n",
    "    function=conn_from_max_node_2_to_conv1.function)\n",
    "\n",
    "  # Remove the old connection to MaxPool node and from MaxPool node, MaxPool node.\n",
    "  ndl_model.net._connections.remove(conn_from_conv0_to_max_node_1)\n",
    "  ndl_model.net._connections.remove(conn_from_max_node_1_to_conv1)\n",
    "  ndl_model.net._nodes.remove(conn_from_conv0_to_max_node_1.post_obj)\n",
    "  \n",
    "  ndl_model.net._connections.remove(conn_from_conv0_to_max_node_2)\n",
    "  ndl_model.net._connections.remove(conn_from_max_node_2_to_conv1)\n",
    "  ndl_model.net._nodes.remove(conn_from_conv0_to_max_node_2.post_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-difference",
   "metadata": {},
   "source": [
    "# Check if modification of connection was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "jewish-folks",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Connection from <Node \"conv2d.0.bias\"> to <Node \"conv2d.0.bias_relay\">> None\n",
      "<Connection from <Node \"conv2d.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d.0\">>> None\n",
      "<Connection from <Node \"input_1\"> to <Neurons of <Ensemble \"conv2d.0\">>> None\n",
      "<Connection from <Node \"conv2d_1.0.bias\"> to <Node \"conv2d_1.0.bias_relay\">> None\n",
      "<Connection from <Node \"conv2d_1.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_1.0\">>> None\n",
      "<Connection from <Node \"conv2d_2.0.bias\"> to <Node \"conv2d_2.0.bias_relay\">> None\n",
      "<Connection from <Node \"conv2d_2.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_2.0\">>> None\n",
      "<Connection from <Node \"dense.0.bias\"> to <TensorNode \"dense.0\">> None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_2.0\">> to <TensorNode \"dense.0\">> Lowpass(tau=0.005)\n",
      "<Connection from <Neurons of <Ensemble \"conv2d.0\">> to <Node \"Custom Node\">> None\n",
      "<Connection from <Node \"Custom Node\"> to <Neurons of <Ensemble \"conv2d_1.0\">>> Lowpass(tau=0.005)\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_1.0\">> to <Node \"Custom Node\">> None\n",
      "<Connection from <Node \"Custom Node\"> to <Neurons of <Ensemble \"conv2d_2.0\">>> Lowpass(tau=0.005)\n"
     ]
    }
   ],
   "source": [
    "for conn in ndl_model.net.all_connections:\n",
    "  print(conn, conn.synapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "opposed-yugoslavia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model.net, minibatch_size=100) as sim:\n",
    "  data2 = sim.predict({ndl_input: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "successful-defendant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data2[ndl_output][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
