{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civic-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nengo_dl\n",
    "import nengo\n",
    "import matplotlib.pyplot as plt\n",
    "from nengo.utils.matplotlib import rasterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "static-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "classical-poison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-sight",
   "metadata": {},
   "source": [
    "# TF Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weird-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(1, 28, 28)) # Channels first.\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=8,\n",
    "    kernel_size=3,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(inp)\n",
    "\n",
    "# Default pool_size = (2,2), padding = \"valid\", data_format = \"channels_last\".\n",
    "max_pool = tf.keras.layers.MaxPool2D(data_format = \"channels_first\")(conv0) \n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(max_pool)\n",
    "\n",
    "# Default pool_size = (2,2), padding = \"valid\", data_format = \"channels_last\".\n",
    "max_pool_1 = tf.keras.layers.MaxPool2D(data_format = \"channels_first\")(conv1) \n",
    "\n",
    "conv2 = tf.keras.layers.Conv2D(\n",
    "    filters=24,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(max_pool_1)\n",
    "\n",
    "# fully connected layer\n",
    "flatten = tf.keras.layers.Flatten()(conv2)\n",
    "dense = tf.keras.layers.Dense(units=10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "charged-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 28, 28)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 26, 26)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 13, 13)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 11, 11)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 5, 5)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 3, 3)          3480      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 6,898\n",
      "Trainable params: 6,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-stylus",
   "metadata": {},
   "source": [
    "# TF Model Compilation and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "worldwide-amazon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Channels first coding.\n",
    "train_images = train_images.reshape([train_images.shape[0], 1] + list(train_images.shape[1:])) # (60000, 1, 28, 28)\n",
    "test_images = test_images.reshape([test_images.shape[0], 1] + list(test_images.shape[1:]))\n",
    "\n",
    "print(train_images.shape, test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cloudy-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4815 - sparse_categorical_accuracy: 0.8772\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9638\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9742\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ac7efeaa950>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.optimizers.Adam(0.001),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "  metrics=[tf.metrics.sparse_categorical_accuracy])\n",
    "model.fit(train_images, train_labels, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-housing",
   "metadata": {},
   "source": [
    "# TF Model evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "included-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0842 - sparse_categorical_accuracy: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08421820402145386, 0.9742000102996826]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-breach",
   "metadata": {},
   "source": [
    "# Conversion from TF to spiking Nengo DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loose-lancaster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:326: UserWarning: Cannot convert max pooling layers to native Nengo objects; consider setting max_to_avg_pool=True to use average pooling instead. Falling back to TensorNode.\n",
      "  % (error_msg + \". \" if error_msg else \"\")\n",
      "/home/rgaurav/miniconda3/envs/latest-nengo-tf/lib/python3.7/site-packages/nengo_dl/converter.py:588: UserWarning: Activation type <function softmax at 0x2ac7d193f8c0> does not have a native Nengo equivalent; falling back to a TensorNode\n",
      "  \"falling back to a TensorNode\" % activation\n"
     ]
    }
   ],
   "source": [
    "n_steps, sfr = 40, 25\n",
    "np.random.seed(100)\n",
    "ndl_model = nengo_dl.Converter(model, \n",
    "                               swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "                               #scale_firing_rates=25, # ISI Nengo DL Acc: 73.5, 74.5\n",
    "                               #scale_firing_rates=50, # ISI Nengo DL Acc: 74\n",
    "                               #scale_firing_rates=100, # ISI Nengo DL Acc: 72.5\n",
    "                               scale_firing_rates=sfr, # ISI Nengo DL Acc: 75.5\n",
    "                               synapse=0.005)\n",
    "\n",
    "with ndl_model.net:\n",
    "  nengo_dl.configure_settings(stateful=False)\n",
    "  conv0_probe = nengo.Probe(ndl_model.layers[conv0]) # Probe All Neurons.\n",
    "  conv1_probe = nengo.Probe(ndl_model.layers[conv1])\n",
    "  conv2_probe = nengo.Probe(ndl_model.layers[conv2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aggressive-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Connection from <Node \"conv2d.0.bias\"> to <Node \"conv2d.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Node \"input_1\"> to <Neurons of <Ensemble \"conv2d.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_1.0.bias\"> to <Node \"conv2d_1.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_1.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <TensorNode \"max_pooling2d\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_1.0\">> to <TensorNode \"max_pooling2d_1\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_2.0.bias\"> to <Node \"conv2d_2.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_2.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_2.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <TensorNode \"max_pooling2d_1\"> to <Neurons of <Ensemble \"conv2d_2.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Node \"dense.0.bias\"> to <TensorNode \"dense.0\">>  | SYNAPSE:  None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_2.0\">> to <TensorNode \"dense.0\">>  | SYNAPSE:  Lowpass(tau=0.005)\n"
     ]
    }
   ],
   "source": [
    "for conn in ndl_model.net._connections:\n",
    "  print(conn, \" | SYNAPSE: \", conn.synapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "educational-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_model.net._connections[6].synapse = nengo.Lowpass(0.005)\n",
    "ndl_model.net._connections[10].synapse = nengo.Lowpass(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "grave-workplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Connection from <Node \"conv2d.0.bias\"> to <Node \"conv2d.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Node \"input_1\"> to <Neurons of <Ensemble \"conv2d.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d.0\">> to <TensorNode \"max_pooling2d\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_1.0.bias\"> to <Node \"conv2d_1.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_1.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <TensorNode \"max_pooling2d\"> to <Neurons of <Ensemble \"conv2d_1.0\">>>  | SYNAPSE:  Lowpass(tau=0.005)\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_1.0\">> to <TensorNode \"max_pooling2d_1\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_2.0.bias\"> to <Node \"conv2d_2.0.bias_relay\">>  | SYNAPSE:  None\n",
      "<Connection from <Node \"conv2d_2.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_2.0\">>>  | SYNAPSE:  None\n",
      "<Connection from <TensorNode \"max_pooling2d_1\"> to <Neurons of <Ensemble \"conv2d_2.0\">>>  | SYNAPSE:  Lowpass(tau=0.005)\n",
      "<Connection from <Node \"dense.0.bias\"> to <TensorNode \"dense.0\">>  | SYNAPSE:  None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_2.0\">> to <TensorNode \"dense.0\">>  | SYNAPSE:  Lowpass(tau=0.005)\n"
     ]
    }
   ],
   "source": [
    "for conn in ndl_model.net._connections:\n",
    "  print(conn, \" | SYNAPSE: \", conn.synapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-weather",
   "metadata": {},
   "source": [
    "# Nengo-DL model test data creation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "industrial-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_test_images = np.tile(\n",
    "  test_images.reshape((test_images.shape[0], 1, -1)), (1, n_steps, 1))\n",
    "ndl_input = ndl_model.inputs[inp]\n",
    "ndl_output = ndl_model.outputs[dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ancient-capture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model.net, minibatch_size=100) as sim:\n",
    "  data1 = sim.predict({ndl_input: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-twins",
   "metadata": {},
   "source": [
    "# Nengo-DL model accuracy (first 200 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reliable-description",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data1[ndl_output][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-collect",
   "metadata": {},
   "source": [
    "## Plot the spike output of `Conv0`, `Conv1`, `Conv2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "empty-batch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv0_spikes = data1[conv0_probe]\n",
    "\n",
    "test_samples, sim_steps, n_neurons = conv0_spikes.shape\n",
    "random_neurons = np.random.choice(n_neurons, 64, replace=False)\n",
    "plt.figure(figsize=(16, 6))\n",
    "rasterplot(np.arange(0, sim_steps)*1e-3, conv0_spikes[0, :, random_neurons].T*sfr*0.001) # For test_sample: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ongoing-sitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv1_spikes = data1[conv1_probe]\n",
    "\n",
    "test_samples, sim_steps, n_neurons = conv1_spikes.shape\n",
    "random_neurons = np.random.choice(n_neurons, 64, replace=False)\n",
    "plt.figure(figsize=(16, 6))\n",
    "rasterplot(np.arange(0, sim_steps)*1e-3, conv1_spikes[0, :, random_neurons].T*sfr*0.001) # For test_sample: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "banned-tablet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv2_spikes = data1[conv2_probe]\n",
    "\n",
    "test_samples, sim_steps, n_neurons = conv2_spikes.shape\n",
    "random_neurons = np.random.choice(n_neurons, 64, replace=False)\n",
    "plt.figure(figsize=(16, 6))\n",
    "rasterplot(np.arange(0, sim_steps)*1e-3, conv2_spikes[0, :, random_neurons].T*sfr*0.001) # For test_sample: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-resolution",
   "metadata": {},
   "source": [
    "# ###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-cleaner",
   "metadata": {},
   "source": [
    "# Nengo-DL model modification (Replacing MaxPooling TensorNode with Custom Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "optimum-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = 4\n",
    "NEURONS_LAST_SPIKED_TS_1, NEURONS_LATEST_ISI_1 = np.zeros((8, 26, 26)), np.ones((8, 26, 26))*np.inf\n",
    "MAX_POOL_MASK_1 = np.ones((8, 26, 26))/num_x\n",
    "\n",
    "def isi_based_max_pooling_mp_1(t, inp):\n",
    "  inp = inp.reshape(8, 26, 26) # Channels first.\n",
    "  ret = np.zeros((8, 13, 13)) # Channels first.\n",
    "  \n",
    "  ##################### Normal MaxPooling with np.max() function. #####################\n",
    "  for chnl in range(inp.shape[0]): # For each channel, calculate the MaxPooled values.\n",
    "    for r in range(13):\n",
    "      for c in range(13):\n",
    "        ret[chnl, r, c] = np.max(inp[chnl, r*2:r*2+2, c*2:c*2+2]) # Channels first\n",
    "#   #####################################################################################\n",
    "  \n",
    "  \n",
    "#   ##################### MaxPooling with ISI based method. ##############################\n",
    "  \n",
    "#   def _isi_max_pool_algorithm(t, x, r1, r2, c1, c2, chnl):\n",
    "#     int_t = int(t*1000.0)\n",
    "#     # Get the local copies of updated NEURONS_LAST_SPIKED_TS, NEURONS_LATEST_ISI, and MAX_POOL_MASK for\n",
    "#     # each timestep.\n",
    "#     neurons_last_spiked_ts = NEURONS_LAST_SPIKED_TS_1[chnl, r1:r2, c1:c2].flatten()\n",
    "#     neurons_latest_isi = NEURONS_LATEST_ISI_1[chnl, r1:r2, c1:c2].flatten()\n",
    "#     max_pool_mask = MAX_POOL_MASK_1[chnl, r1:r2, c1:c2].flatten()\n",
    "    \n",
    "#     spiked_neurons_mask = np.logical_not(np.isin(x, 0))\n",
    "#     if np.all(spiked_neurons_mask == False):\n",
    "#       return 0\n",
    "    \n",
    "#     if np.any(neurons_last_spiked_ts[spiked_neurons_mask]):\n",
    "#       neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "#       neurons_isi_to_be_updated = neurons_last_spiked_ts_mask & spiked_neurons_mask\n",
    "#       neurons_latest_isi[neurons_isi_to_be_updated] = int_t - neurons_last_spiked_ts[neurons_isi_to_be_updated]\n",
    "#       max_pool_mask[:] = np.zeros(num_x)\n",
    "#       max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "#       neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "      \n",
    "#       NEURONS_LAST_SPIKED_TS_1[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "#       NEURONS_LATEST_ISI_1[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "#       MAX_POOL_MASK_1[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "      \n",
    "#       return np.dot(max_pool_mask, x)\n",
    "    \n",
    "#     else:\n",
    "#       if np.min(neurons_latest_isi) != np.inf:\n",
    "#         max_pool_mask[:] = np.zeros(num_x)\n",
    "#         max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "#         neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#       else:\n",
    "#         if np.any(neurons_last_spiked_ts):\n",
    "#           neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "#           minimum_last_spiked_ts = np.min(neurons_last_spiked_ts[neurons_last_spiked_ts_mask])\n",
    "#           first_spike_neuron_index = np.where(neurons_last_spiked_ts == minimum_last_spiked_ts)[0][0]\n",
    "#           max_pool_mask[:] = np.zeros(num_x)\n",
    "#           max_pool_mask[first_spike_neuron_index] = 1.0\n",
    "#           neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#         else:\n",
    "#           neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#           max_pool_mask[:] = np.zeros(num_x)\n",
    "#           max_pool_mask[np.where(neurons_last_spiked_ts)[0][0]] = 1.0\n",
    "       \n",
    "#       NEURONS_LAST_SPIKED_TS_1[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "#       NEURONS_LATEST_ISI_1[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "#       MAX_POOL_MASK_1[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "#       return np.dot(max_pool_mask, x)\n",
    "    \n",
    "#   for chnl in range(inp.shape[0]):\n",
    "#     for r in range(13):\n",
    "#       for c in range(13):\n",
    "#         ret[chnl, r, c] = _isi_max_pool_algorithm(\n",
    "#             t, inp[chnl, r*2:r*2+2, c*2:c*2+2].flatten(), r*2, r*2+2, c*2, c*2+2, chnl)\n",
    "  \n",
    "  return ret.flatten()\n",
    "#   #return x[:5408]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplified_isi_based_max_pooling():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "anticipated-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = 4\n",
    "NEURONS_LAST_SPIKED_TS_2, NEURONS_LATEST_ISI_2 = np.zeros((16, 11, 11)), np.ones((16, 11, 11))*np.inf\n",
    "MAX_POOL_MASK_2 = np.ones((16, 11, 11))/num_x\n",
    "\n",
    "def isi_based_max_pooling_mp_2(t, inp):\n",
    "  inp = inp.reshape(16, 11, 11) # Channels first.\n",
    "  ret = np.zeros((16, 5, 5)) # Channels first.\n",
    "  \n",
    "  ##################### Normal MaxPooling with np.max() function. #####################\n",
    "  for chnl in range(inp.shape[0]): # For each channel, calculate the MaxPooled values.\n",
    "    for r in range(5):\n",
    "      for c in range(5):\n",
    "        ret[chnl, r, c] = np.max(inp[chnl, r*2:r*2+2, c*2:c*2+2]) # Channels first\n",
    "  #####################################################################################\n",
    "  \n",
    "  \n",
    "#   ##################### MaxPooling with ISI based method. ##############################\n",
    "  \n",
    "#   def _isi_max_pool_algorithm(t, x, r1, r2, c1, c2, chnl):\n",
    "#     int_t = int(t*1000.0)\n",
    "#     # Get the local copies of updated NEURONS_LAST_SPIKED_TS, NEURONS_LATEST_ISI, and MAX_POOL_MASK for\n",
    "#     # each timestep.\n",
    "#     neurons_last_spiked_ts = NEURONS_LAST_SPIKED_TS_2[chnl, r1:r2, c1:c2].flatten()\n",
    "#     neurons_latest_isi = NEURONS_LATEST_ISI_2[chnl, r1:r2, c1:c2].flatten()\n",
    "#     max_pool_mask = MAX_POOL_MASK_2[chnl, r1:r2, c1:c2].flatten()\n",
    "    \n",
    "#     spiked_neurons_mask = np.logical_not(np.isin(x, 0))\n",
    "#     if np.all(spiked_neurons_mask == False):\n",
    "#       return 0\n",
    "    \n",
    "#     if np.any(neurons_last_spiked_ts[spiked_neurons_mask]):\n",
    "#       neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "#       neurons_isi_to_be_updated = neurons_last_spiked_ts_mask & spiked_neurons_mask\n",
    "#       neurons_latest_isi[neurons_isi_to_be_updated] = int_t - neurons_last_spiked_ts[neurons_isi_to_be_updated]\n",
    "#       max_pool_mask[:] = np.zeros(num_x)\n",
    "#       max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "#       neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "      \n",
    "#       NEURONS_LAST_SPIKED_TS_2[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "#       NEURONS_LATEST_ISI_2[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "#       MAX_POOL_MASK_2[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "      \n",
    "#       return np.dot(max_pool_mask, x)\n",
    "    \n",
    "#     else:\n",
    "#       if np.min(neurons_latest_isi) != np.inf:\n",
    "#         max_pool_mask[:] = np.zeros(num_x)\n",
    "#         max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "#         neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#       else:\n",
    "#         if np.any(neurons_last_spiked_ts):\n",
    "#           neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "#           minimum_last_spiked_ts = np.min(neurons_last_spiked_ts[neurons_last_spiked_ts_mask])\n",
    "#           first_spike_neuron_index = np.where(neurons_last_spiked_ts == minimum_last_spiked_ts)[0][0]\n",
    "#           max_pool_mask[:] = np.zeros(num_x)\n",
    "#           max_pool_mask[first_spike_neuron_index] = 1.0\n",
    "#           neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#         else:\n",
    "#           neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "#           max_pool_mask[:] = np.zeros(num_x)\n",
    "#           max_pool_mask[np.where(neurons_last_spiked_ts)[0][0]] = 1.0\n",
    "       \n",
    "#       NEURONS_LAST_SPIKED_TS_2[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "#       NEURONS_LATEST_ISI_2[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "#       MAX_POOL_MASK_2[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "#       return np.dot(max_pool_mask, x)\n",
    "    \n",
    "#   for chnl in range(inp.shape[0]):\n",
    "#     for r in range(5):\n",
    "#       for c in range(5):\n",
    "#         ret[chnl, r, c] = _isi_max_pool_algorithm(\n",
    "#             t, inp[chnl, r*2:r*2+2, c*2:c*2+2].flatten(), r*2, r*2+2, c*2, c*2+2, chnl)\n",
    "  \n",
    "  return ret.flatten()\n",
    "#   #return x[:5408]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acquired-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ndl_model.net:\n",
    "  # Create Custom Node.\n",
    "  new_node_1 = nengo.Node(output=isi_based_max_pooling_mp_1, size_in=5408, label=\"Custom Node\")\n",
    "  new_node_2 = nengo.Node(output=isi_based_max_pooling_mp_2, size_in=1936, label=\"Custom Node\")\n",
    "\n",
    "  conn_from_conv0_to_max_node_1 = ndl_model.net.all_connections[3]\n",
    "  # COnnection from Conv0 to MaxPool node.\n",
    "  nengo.Connection(\n",
    "    conn_from_conv0_to_max_node_1.pre_obj,\n",
    "    new_node_1,\n",
    "    transform=conn_from_conv0_to_max_node_1.transform,\n",
    "    synapse=conn_from_conv0_to_max_node_1.synapse,\n",
    "    function=conn_from_conv0_to_max_node_1.function)\n",
    "\n",
    "  # Connection from MaxPool node to Conv1.\n",
    "  conn_from_max_node_1_to_conv1 = ndl_model.net.all_connections[6]\n",
    "  nengo.Connection(\n",
    "    new_node_1,\n",
    "    conn_from_max_node_1_to_conv1.post_obj,\n",
    "    transform=conn_from_max_node_1_to_conv1.transform,\n",
    "    synapse=conn_from_max_node_1_to_conv1.synapse,\n",
    "    function=conn_from_max_node_1_to_conv1.function)\n",
    "  \n",
    "  #################################################################\n",
    "  \n",
    "  conn_from_conv0_to_max_node_2 = ndl_model.net.all_connections[7]\n",
    "  # COnnection from Conv0 to MaxPool node.\n",
    "  nengo.Connection(\n",
    "    conn_from_conv0_to_max_node_2.pre_obj,\n",
    "    new_node_2,\n",
    "    transform=conn_from_conv0_to_max_node_2.transform,\n",
    "    synapse=conn_from_conv0_to_max_node_2.synapse,\n",
    "    function=conn_from_conv0_to_max_node_2.function)\n",
    "\n",
    "  # Connection from MaxPool node to Conv1.\n",
    "  conn_from_max_node_2_to_conv1 = ndl_model.net.all_connections[10]\n",
    "  nengo.Connection(\n",
    "    new_node_2,\n",
    "    conn_from_max_node_2_to_conv1.post_obj,\n",
    "    transform=conn_from_max_node_2_to_conv1.transform,\n",
    "    synapse=conn_from_max_node_2_to_conv1.synapse,\n",
    "    function=conn_from_max_node_2_to_conv1.function)\n",
    "\n",
    "  # Remove the old connection to MaxPool node and from MaxPool node, MaxPool node.\n",
    "  ndl_model.net._connections.remove(conn_from_conv0_to_max_node_1)\n",
    "  ndl_model.net._connections.remove(conn_from_max_node_1_to_conv1)\n",
    "  ndl_model.net._nodes.remove(conn_from_conv0_to_max_node_1.post_obj)\n",
    "  \n",
    "  ndl_model.net._connections.remove(conn_from_conv0_to_max_node_2)\n",
    "  ndl_model.net._connections.remove(conn_from_max_node_2_to_conv1)\n",
    "  ndl_model.net._nodes.remove(conn_from_conv0_to_max_node_2.post_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-difference",
   "metadata": {},
   "source": [
    "# Check if modification of connection was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "jewish-folks",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Connection from <Node \"conv2d.0.bias\"> to <Node \"conv2d.0.bias_relay\">> None\n",
      "<Connection from <Node \"conv2d.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d.0\">>> None\n",
      "<Connection from <Node \"input_1\"> to <Neurons of <Ensemble \"conv2d.0\">>> None\n",
      "<Connection from <Node \"conv2d_1.0.bias\"> to <Node \"conv2d_1.0.bias_relay\">> None\n",
      "<Connection from <Node \"conv2d_1.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_1.0\">>> None\n",
      "<Connection from <Node \"conv2d_2.0.bias\"> to <Node \"conv2d_2.0.bias_relay\">> None\n",
      "<Connection from <Node \"conv2d_2.0.bias_relay\"> to <Neurons of <Ensemble \"conv2d_2.0\">>> None\n",
      "<Connection from <Node \"dense.0.bias\"> to <TensorNode \"dense.0\">> None\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_2.0\">> to <TensorNode \"dense.0\">> Lowpass(tau=0.005)\n",
      "<Connection from <Neurons of <Ensemble \"conv2d.0\">> to <Node \"Custom Node\">> None\n",
      "<Connection from <Node \"Custom Node\"> to <Neurons of <Ensemble \"conv2d_1.0\">>> Lowpass(tau=0.005)\n",
      "<Connection from <Neurons of <Ensemble \"conv2d_1.0\">> to <Node \"Custom Node\">> None\n",
      "<Connection from <Node \"Custom Node\"> to <Neurons of <Ensemble \"conv2d_2.0\">>> Lowpass(tau=0.005)\n"
     ]
    }
   ],
   "source": [
    "for conn in ndl_model.net.all_connections:\n",
    "  print(conn, conn.synapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "opposed-yugoslavia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Constructing graph: build stage finished in 0:00:00                            \r"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model.net, minibatch_size=100) as sim:\n",
    "  data2 = sim.predict({ndl_input: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "successful-defendant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data2[ndl_output][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
