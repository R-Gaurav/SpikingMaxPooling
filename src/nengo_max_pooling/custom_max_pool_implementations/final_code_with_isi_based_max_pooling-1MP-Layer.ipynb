{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civic-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nengo_dl\n",
    "import nengo\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "static-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "classical-poison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-sight",
   "metadata": {},
   "source": [
    "# TF Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "inp = tf.keras.Input(shape=(1, 28, 28)) # Channels first.\n",
    "\n",
    "# convolutional layers\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=16,\n",
    "    kernel_size=3,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(inp)\n",
    "\n",
    "# Default pool_size = (2,2), padding = \"valid\", data_format = \"channels_last\".\n",
    "max_pool = tf.keras.layers.MaxPool2D(data_format = \"channels_first\")(conv0) \n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=24,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    "    data_format=\"channels_first\"\n",
    ")(max_pool)\n",
    "\n",
    "# fully connected layer\n",
    "flatten = tf.keras.layers.Flatten()(conv1)\n",
    "dense = tf.keras.layers.Dense(units=10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-stylus",
   "metadata": {},
   "source": [
    "# TF Model Compilation and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-amazon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Channels first coding.\n",
    "train_images = train_images.reshape([train_images.shape[0], 1] + list(train_images.shape[1:])) # (60000, 1, 28, 28)\n",
    "test_images = test_images.reshape([test_images.shape[0], 1] + list(test_images.shape[1:]))\n",
    "\n",
    "print(train_images.shape, test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.optimizers.Adam(0.001),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "  metrics=[tf.metrics.sparse_categorical_accuracy])\n",
    "model.fit(train_images, train_labels, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-housing",
   "metadata": {},
   "source": [
    "# TF Model evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-breach",
   "metadata": {},
   "source": [
    "# Conversion from TF to spiking Nengo DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 40\n",
    "np.random.seed(100)\n",
    "ndl_model = nengo_dl.Converter(model, \n",
    "                               swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "                               scale_firing_rates=25,\n",
    "                               synapse=0.005)\n",
    "\n",
    "with ndl_model.net:\n",
    "  nengo_dl.configure_settings(stateful=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before:\", ndl_model.net._connections[3], ndl_model.net._connections[3].synapse)\n",
    "#ndl_model.net._connections[3].synapse = nengo.Lowpass(0.005)\n",
    "print(\"After:\", ndl_model.net._connections[3], ndl_model.net._connections[3].synapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-weather",
   "metadata": {},
   "source": [
    "# Nengo-DL model test data creation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl_test_images = np.tile(\n",
    "  test_images.reshape((test_images.shape[0], 1, -1)), (1, n_steps, 1))\n",
    "ndl_input = ndl_model.inputs[inp]\n",
    "ndl_output = ndl_model.outputs[dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model.net, minibatch_size=100) as sim:\n",
    "  data1 = sim.predict({ndl_input: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-twins",
   "metadata": {},
   "source": [
    "# Nengo-DL model accuracy (first 200 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data1[ndl_output][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-resolution",
   "metadata": {},
   "source": [
    "# ###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-cleaner",
   "metadata": {},
   "source": [
    "# Nengo-DL model modification (Replacing MaxPooling TensorNode with Custom Node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = 4\n",
    "NEURONS_LAST_SPIKED_TS, NEURONS_LATEST_ISI = np.zeros((32, 26, 26)), np.ones((32, 26, 26))*np.inf\n",
    "MAX_POOL_MASK = np.ones((32, 26, 26))/num_x\n",
    "\n",
    "def isi_based_max_pooling(t, inp):\n",
    "  # Reshape `inp` of shape (21632,) to matrix of shape (26, 26, 32). This operation should preserve the input\n",
    "  # topography from the first Conv layer.\n",
    "  # inp = inp.reshape(26, 26, 32) # Channels last.\n",
    "  # print(inp[:1000])\n",
    "  inp = inp.reshape(32, 26, 26) # Channels first.\n",
    "  # Now the output with 2 x 2 MaxPooling should be of shape (13, 13, 32) and then flattened.\n",
    "  # ret = np.zeros((13, 13, 32)) # Channels last.\n",
    "  ret = np.zeros((32, 13, 13)) # Channels first.\n",
    "  \n",
    "  ##################### Normal MaxPooling with np.max() function. #####################\n",
    "#   #for chnl in range(inp.shape[2]): # For each channel, calculate the MaxPooled values.\n",
    "#   for chnl in range(inp.shape[0]): # For each channel, calculate the MaxPooled values.\n",
    "#     for r in range(13):\n",
    "#       for c in range(13):\n",
    "#         ret[chnl, r, c] = np.max(inp[chnl, r*2:r*2+2, c*2:c*2+2]) # Channels first\n",
    "#         #ret[r, c, chnl] = np.max(inp[r*2:r*2+2, c*2:c*2+2, chnl]) # Channels last\n",
    "  #####################################################################################\n",
    "  \n",
    "  \n",
    "  ##################### MaxPooling with ISI based method. ##############################\n",
    "  \n",
    "  def _isi_max_pool_algorithm(t, x, r1, r2, c1, c2, chnl):\n",
    "    int_t = int(t*1000.0)\n",
    "    # Get the local copies of updated NEURONS_LAST_SPIKED_TS, NEURONS_LATEST_ISI, and MAX_POOL_MASK for\n",
    "    # each timestep.\n",
    "    neurons_last_spiked_ts = NEURONS_LAST_SPIKED_TS[chnl, r1:r2, c1:c2].flatten()\n",
    "    neurons_latest_isi = NEURONS_LATEST_ISI[chnl, r1:r2, c1:c2].flatten()\n",
    "    max_pool_mask = MAX_POOL_MASK[chnl, r1:r2, c1:c2].flatten()\n",
    "    \n",
    "    spiked_neurons_mask = np.logical_not(np.isin(x, 0))\n",
    "    if np.all(spiked_neurons_mask == False):\n",
    "      return 0\n",
    "    \n",
    "    if np.any(neurons_last_spiked_ts[spiked_neurons_mask]):\n",
    "      neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "      neurons_isi_to_be_updated = neurons_last_spiked_ts_mask & spiked_neurons_mask\n",
    "      neurons_latest_isi[neurons_isi_to_be_updated] = int_t - neurons_last_spiked_ts[neurons_isi_to_be_updated]\n",
    "      max_pool_mask[:] = np.zeros(num_x)\n",
    "      max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "      neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "      \n",
    "      NEURONS_LAST_SPIKED_TS[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "      NEURONS_LATEST_ISI[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "      MAX_POOL_MASK[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "      \n",
    "      return np.dot(max_pool_mask, x)\n",
    "    \n",
    "    else:\n",
    "      if np.min(neurons_latest_isi) != np.inf:\n",
    "        max_pool_mask[:] = np.zeros(num_x)\n",
    "        max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "        neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "      else:\n",
    "        if np.any(neurons_last_spiked_ts):\n",
    "          neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "          minimum_last_spiked_ts = np.min(neurons_last_spiked_ts[neurons_last_spiked_ts_mask])\n",
    "          first_spike_neuron_index = np.where(neurons_last_spiked_ts == minimum_last_spiked_ts)\n",
    "          max_pool_mask[:] = np.zeros(num_x)\n",
    "          max_pool_mask[first_spike_neuron_index] = 1.0\n",
    "          neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "        else:\n",
    "          neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "          max_pool_mask[:] = np.zeros(num_x)\n",
    "          max_pool_mask[np.where(neurons_last_spiked_ts)[0]] = 1.0\n",
    "       \n",
    "      NEURONS_LAST_SPIKED_TS[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "      NEURONS_LATEST_ISI[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "      MAX_POOL_MASK[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "      return np.dot(max_pool_mask, x)\n",
    "    \n",
    "  for chnl in range(inp.shape[0]):\n",
    "    for r in range(13):\n",
    "      for c in range(13):\n",
    "        ret[chnl, r, c] = _isi_max_pool_algorithm(\n",
    "            t, inp[chnl, r*2:r*2+2, c*2:c*2+2].flatten(), r*2, r*2+2, c*2, c*2+2, chnl)\n",
    "  \n",
    "  return ret.flatten()\n",
    "  #return x[:5408]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = 4\n",
    "NEURONS_LAST_SPIKED_TS_1, NEURONS_LATEST_ISI_1 = np.zeros((32, 26, 26)), np.ones((32, 26, 26))*np.inf\n",
    "MAX_POOL_MASK_1 = np.ones((32, 26, 26))/num_x\n",
    "\n",
    "def isi_based_max_pooling_mp_1(t, inp):\n",
    "  inp = inp.reshape(32, 26, 26) # Channels first.\n",
    "  ret = np.zeros((32, 13, 13)) # Channels first.\n",
    "  \n",
    "  ##################### Normal MaxPooling with np.max() function. #####################\n",
    "#   #for chnl in range(inp.shape[2]): # For each channel, calculate the MaxPooled values.\n",
    "#   for chnl in range(inp.shape[0]): # For each channel, calculate the MaxPooled values.\n",
    "#     for r in range(13):\n",
    "#       for c in range(13):\n",
    "#         ret[chnl, r, c] = np.max(inp[chnl, r*2:r*2+2, c*2:c*2+2]) # Channels first\n",
    "#         #ret[r, c, chnl] = np.max(inp[r*2:r*2+2, c*2:c*2+2, chnl]) # Channels last\n",
    "  #####################################################################################\n",
    "  \n",
    "  \n",
    "  ##################### MaxPooling with ISI based method. ##############################\n",
    "  \n",
    "  def _isi_max_pool_algorithm(t, x, r1, r2, c1, c2, chnl):\n",
    "    int_t = int(t*1000.0)\n",
    "    # Get the local copies of updated NEURONS_LAST_SPIKED_TS, NEURONS_LATEST_ISI, and MAX_POOL_MASK for\n",
    "    # each timestep.\n",
    "    neurons_last_spiked_ts = NEURONS_LAST_SPIKED_TS_1[chnl, r1:r2, c1:c2].flatten()\n",
    "    neurons_latest_isi = NEURONS_LATEST_ISI_1[chnl, r1:r2, c1:c2].flatten()\n",
    "    max_pool_mask = MAX_POOL_MASK_1[chnl, r1:r2, c1:c2].flatten()\n",
    "    \n",
    "    spiked_neurons_mask = np.logical_not(np.isin(x, 0))\n",
    "    if np.all(spiked_neurons_mask == False):\n",
    "      return 0\n",
    "    \n",
    "    if np.any(neurons_last_spiked_ts[spiked_neurons_mask]):\n",
    "      neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "      neurons_isi_to_be_updated = neurons_last_spiked_ts_mask & spiked_neurons_mask\n",
    "      neurons_latest_isi[neurons_isi_to_be_updated] = int_t - neurons_last_spiked_ts[neurons_isi_to_be_updated]\n",
    "      max_pool_mask[:] = np.zeros(num_x)\n",
    "      max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "      neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "      \n",
    "      NEURONS_LAST_SPIKED_TS_1[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "      NEURONS_LATEST_ISI_1[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "      MAX_POOL_MASK_1[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "      \n",
    "      return np.dot(max_pool_mask, x)\n",
    "    \n",
    "    else:\n",
    "      if np.min(neurons_latest_isi) != np.inf:\n",
    "        max_pool_mask[:] = np.zeros(num_x)\n",
    "        max_pool_mask[np.argmin(neurons_latest_isi)] = 1.0\n",
    "        neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "      else:\n",
    "        if np.any(neurons_last_spiked_ts):\n",
    "          neurons_last_spiked_ts_mask = np.logical_not(np.isin(neurons_last_spiked_ts, 0))\n",
    "          minimum_last_spiked_ts = np.min(neurons_last_spiked_ts[neurons_last_spiked_ts_mask])\n",
    "          first_spike_neuron_index = np.where(neurons_last_spiked_ts == minimum_last_spiked_ts)[0][0]\n",
    "          max_pool_mask[:] = np.zeros(num_x)\n",
    "          max_pool_mask[first_spike_neuron_index] = 1.0\n",
    "          neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "        else:\n",
    "          neurons_last_spiked_ts[spiked_neurons_mask] = int_t\n",
    "          max_pool_mask[:] = np.zeros(num_x)\n",
    "          max_pool_mask[np.where(neurons_last_spiked_ts)[0][0]] = 1.0\n",
    "       \n",
    "      NEURONS_LAST_SPIKED_TS_1[chnl, r1:r2, c1:c2] = neurons_last_spiked_ts.reshape(2, 2)\n",
    "      NEURONS_LATEST_ISI_1[chnl, r1:r2, c1:c2] = neurons_latest_isi.reshape(2, 2)\n",
    "      MAX_POOL_MASK_1[chnl, r1:r2, c1:c2] = max_pool_mask.reshape(2, 2)\n",
    "      return np.dot(max_pool_mask, x)\n",
    "    \n",
    "  for chnl in range(inp.shape[0]):\n",
    "    for r in range(13):\n",
    "      for c in range(13):\n",
    "        ret[chnl, r, c] = _isi_max_pool_algorithm(\n",
    "            t, inp[chnl, r*2:r*2+2, c*2:c*2+2].flatten(), r*2, r*2+2, c*2, c*2+2, chnl)\n",
    "  \n",
    "  return ret.flatten()\n",
    "  #return x[:5408]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ndl_model.net:\n",
    "  # Create Custom Node.\n",
    "  new_node = nengo.Node(output=isi_based_max_pooling, size_in=21632, label=\"Custom Node\")\n",
    "\n",
    "  conn_from_conv0_to_max_node = ndl_model.net.all_connections[3]\n",
    "\n",
    "  # COnnection from Conv0 to MaxPool node.\n",
    "  nengo.Connection(\n",
    "    conn_from_conv0_to_max_node.pre_obj,\n",
    "    new_node,\n",
    "    transform=conn_from_conv0_to_max_node.transform,\n",
    "    synapse=conn_from_conv0_to_max_node.synapse,\n",
    "    function=conn_from_conv0_to_max_node.function)\n",
    "\n",
    "  # Connection from MaxPool node to Conv1.\n",
    "  conn_from_max_node_to_conv1 = ndl_model.net.all_connections[6]\n",
    "  nengo.Connection(\n",
    "    new_node,\n",
    "    conn_from_max_node_to_conv1.post_obj,\n",
    "    transform=conn_from_max_node_to_conv1.transform,\n",
    "    synapse=conn_from_max_node_to_conv1.synapse,\n",
    "    function=conn_from_max_node_to_conv1.function)\n",
    "\n",
    "  # Remove the old connection to MaxPool node and from MaxPool node, MaxPool node.\n",
    "  ndl_model.net._connections.remove(conn_from_conv0_to_max_node)\n",
    "  ndl_model.net._connections.remove(conn_from_max_node_to_conv1)\n",
    "  ndl_model.net._nodes.remove(conn_from_conv0_to_max_node.post_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-difference",
   "metadata": {},
   "source": [
    "# Check if modification of connection was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-folks",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for conn in ndl_model.net.all_connections:\n",
    "  print(conn, conn.synapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-yugoslavia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with nengo_dl.Simulator(\n",
    "  ndl_model.net, minibatch_size=100) as sim:\n",
    "  data2 = sim.predict({ndl_input: ndl_test_images[:200]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-defendant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for pred, true in zip(data2[ndl_output][:, -1, :], test_labels):\n",
    "  if np.argmax(pred) == true:\n",
    "    acc += 1\n",
    "print(acc/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-ukraine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
